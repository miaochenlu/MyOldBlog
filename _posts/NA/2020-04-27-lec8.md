---
title: "Approximation Theory"
tags: Numarical_Analysis
key: page-NA8



---

<!--more-->



给定$x_1,\cdots,x_m$, 以及$y_1,\cdots,y_m$, 找一个更简单的函数$P(x)\approx f(x)$

但是

* m通常很大
* $y_i$是实验数据，并不精确，也就是说$y_i\not= f(x_i)$

我们的目标是找到best fit $P(x)$ 使得误差$P(x_i)-y_i$对所有数据点都小

Options:

* minimize $\underset{1\leq i\leq m}{max}\vert P(x_i)-y_i\vert$  minmax problem 最大的误差最小化(对应∞范数)
* minimize $\sum_{i=1}^m\vert P(x_i)-y_i\vert$ absolute deviation 对应L-1范数
* minimize $\sum_{i=1}^m \vert P(x_i)-y_i\vert ^2$ least-squares method 对应L-2范数



# 1. Discrete Least Squares Approximation

Determine the polynomial $P_n(x)=a_0+a_1x+\cdots+a_nx^n$ to approximate a set of data $\{(x_i,y_i)\vert i=1,2,\cdots,m\}$ such that least squares error $E_2=\sum_{i=1}^m[P_n(x_i)-y_i]^2$ is minimized.

Here, $n<<m$

事实上，$E_2$是$a_0,a_1,\cdots,a_n$的函数，即

$$E_2(a_0,a_1,\cdots,a_n)=\sum_{i=1}^m[a_0+a_1x_i+\cdots+a_nx_i^n-y_i]^2$$

要最小化$E_2$, 则要使$\frac{\partial E_2}{\partial a_k}=0,k=0,\cdots,n$

$$\begin{aligned}0&=\frac{\partial E_2}{\partial a_k}\\&=2\sum_{i=1}^m[P_n(x_i)-y_i]\cdot \frac{\partial P_n(x_i)}{\partial a_k}\\&=2\sum_{i=1}^m[\sum_{j=0}^na_jx_i^j-y_i]x_i^k\\&=2(\sum_{j=0}^na_j(\sum_{i=1}^mx_i^{j+k})-\sum_{i=1}^my_ix_i^k )\end{aligned}$$

令$b_k=\sum_{i=1}^m x_i^k, c_k=\sum_{i=1}^my_ix_i^k$

对所有$a_k$求导，写成矩阵形式

$$\left[\begin{matrix}b_{0+0}&\cdots&b_{0+n}\\\vdots&\vdots&\vdots\\ b_{n+0}&\cdots&b_{n+n} \end{matrix}\right]\left[\begin{matrix}a_0\\\vdots \\a_n\end{matrix}\right]=\left[\begin{matrix}c_0\\ \vdots\\ c_n\end{matrix}\right]$$



另一种推导方式

$$\begin{aligned}P(x)=&\alpha_0x^0+\alpha_1x^1+\cdots+\alpha_nx^n\\=&(x^0, x^1,\cdots,x^n)\left[\begin{matrix}\alpha_0\\\alpha_1\\\vdots\\\alpha_n\end{matrix}\right]  =(\phi(x))(a)\end{aligned}$$

$$E=e_i^2=\left\Vert\begin{matrix}e_1\\\cdots\\c_n\end{matrix}\right\Vert_2^2$$

$e_i=(\phi(x_i))(a)-y_i$

$$\left[\begin{matrix}e_1\\\cdots\\e_n\end{matrix}\right]=\left[\begin{matrix}\phi(x_1)\\\vdots\\ \phi(x_n)\end{matrix}\right] \left[\begin{matrix}a_0\\\vdots \\a_n \end{matrix}\right]-\left[\begin{matrix}y_0\\ \vdots\\y_n\end{matrix}\right]$$

简化写成$e=Aa-y$

$E_2=\Vert e\Vert_2^2=e^Te=(Aa-y)^T(Aa-y)$

$=(a^TA^T-y^T)(Aa-y)$

因此$E_2(a)=a^TA^TAa-2a^TA^Ty+Y^Ty$

$\frac{\partial E_2}{\partial a}=0=2A^TAa-2A^Ty$

So, $(A^TA)a=A^Ty$

令$B=A^TA, C=A^Ty$

则可以写成$Ba=C$

<br>



# 2. Orthogonal Polynomials and Least Squares Approximation

### 1. Inner Product

A map $V\times V\rightarrow F$ with 3 axioms

* conjugate symmetry(x和y的内积等于y和x的内积)

$$<x,y>=\overline{<y,x>}$$

* Linearity

$$<ax,y>=a<x,y>,\quad<x+y,z>=<x,z>+<y,z>$$

* Positive-definiteness

$$<x,x>\;\geq 0,\quad <x,x>=0\Rightarrow x=0 $$

内积和范数的关系

Inner product defines a norm of $x$ as $\Vert x\Vert_2=\sqrt{<x,x>}$

扩展到向量和函数

* Discrete

$$\sum_{i} f_ig_i=\left[ \begin{matrix} f_1\;f_2&\cdots f_n\end{matrix}\right] \left[\begin{matrix}g_1\\g_2\\\cdots\\g_n\end{matrix}\right]=(f)^T(g)$$

* Continous

$$\int_a^b f(x)g(x)dx$$

<br>

> $f$ and $g$ are said to be ***orthogonal*** if $(f,g)=0$



### 2. Weight(metrix)

$<f,g>_w$:

* Discrete

$$\begin{aligned}\sum_{i} w_if_ig_i=&\left[\begin{matrix}f_1&f_2&\cdots&f_n\end{matrix}\right]\left[\begin{matrix}w_1&0&\cdots&0\\0&w_2&\cdots&0\\\vdots&\vdots&\ddots&\vdots\\0&0&\cdots&w_n\end{matrix}\right]\left[\begin{matrix}g_1\\g_2\\\vdots\\g_n\end{matrix}\right]\\=&(f)^T[w](g)\end{aligned}$$

* Continous

$$\int_a^b w(x)f(x)g(x)dx$$

<br>

为什么要有这个东西呢？

考虑我们解方程得到了一个误差

$$\left\Vert\begin{matrix}e_1\\e_2\\\cdots\\e_n\end{matrix}\right\Vert_2$$

假设我们不在乎$x_1$的误差，特别在乎$x_2$的误差

那我们可以写出

$$E=0.1e_1^2+10e_2^2+\cdots$$

相当于每个$e_i$前面乘上了一个权重

$$E=e^T\left[\begin{matrix}0.1&0\\0&10\end{matrix}\right]e=e^Twe$$

<br>

回到原来的问题

* Given $x_1,\cdots,x_m$ and $y_1,\cdots,y_m$. Find a simpler function $P(x)\approx f(x)$ such that $E=\sum_{i=1}^m\vert P(x_i)-y_i\vert^2$ is minimized

* Given a function $f(x)$ defined on $[a,b]$. Find a simpler function $P(x)\approx f(x)$ such that $E=\int_a^b[P(x)-f(x)]^2dx$ is minimized.



#### Linearly Independent Functions

`Definition`{:.warning}

The set of functions $\{\varphi_0(x),\varphi_1(x),\cdots,\varphi_n(x) \}$ is said to be ***Linearly independent*** on $[a,b]$ if, whenever

$$a_0\varphi_0(x)+a_1\varphi_1(x)+\cdots+a_n\varphi_n(x)=0\quad for\;all\;x\in [a,b]$$

we have $a_0=a_1=\cdots=a_n=0$. Otherwise the set of functiosn is said to be ***linearly dependent***

<br>

`Theorem`{:.error}

If $\varphi_j(x)$ is a polynomial of degree $j$ for each $j=0,\cdots,n$, then $\{\varphi_0(x),\varphi_1(x),\cdots,\varphi_n(x))\}$ is linearly independent on any interval $[a,b]$

<br>

`Theorem`{:.error}

Let $\Pi_n$ be the set of all polynomials of degree at most $n$. If $\{\varphi_0(x),\varphi_1(x),\cdots,\varphi_n(x) \}$ is a collection of  linearly independent polynomials in $\Pi_n$, then any polynomials in $\Pi_n$ can be written uniquely as a linear combination of $\varphi_0(x),\varphi_1(x),\cdots,\varphi_n(x)$

<br>

`Definition`{:.warning}

For a general linear independent set of functions $\{\varphi_0(x),\varphi_1(x),\cdots,\varphi_n(x) \}$, a linear combination of $\varphi_0(x),\varphi_1(x),\cdots,\varphi_n(x)$, $P(x)=\sum_{j=0}^n a_j\varphi_j(x)$ is called a **generalized polynomial**



### Approximation

In a space spanned $\{\varphi_i(x)\}$, find the one that is closest to $f$

* The element in the space

$$P(a,x)=\sum_i a_i\phi_i(x)=(\phi(x))^T(a)$$

* The distance(error) between $P(a)$ and $f$

$$E(a)=E(a_0,\cdots,a_n)=\Vert P(a)-f\Vert^2=<\phi(x_i)a-f,\cdots>$$

$=a^T\varphi\varphi^T a-2a^T\varphi f+f^Tf$

$$E=e_i^2=\left\Vert\begin{matrix}e_1\\\cdots\\e_n\end{matrix}\right\Vert_2^2$$

$e_i=(\phi(x_i))^T(a)-f_i$

$$\left[\begin{matrix}e_1\\\cdots\\e_n\end{matrix}\right]=\left[\begin{matrix}\phi(x_1)^T\\\vdots\\ \phi(x_n)^T\end{matrix}\right] \left[\begin{matrix}a_0\\\vdots \\a_n \end{matrix}\right]-\left[\begin{matrix}y_0\\ \vdots\\y_n\end{matrix}\right]$$

简化写成$e=\phi a-f$

$E_2=\Vert e\Vert_2^2=e^Te=(\phi^T a-f)^T(\phi^T a-f)$

$=(a^T\phi-f^T)(\phi^T a-y)$

因此$E(a)=a^T\phi\phi^T a-2a^T\phi f+f^Tf$

* minimize the distance

$0=\frac{\partial E}{\partial a}=2\phi\phi^T a-2\phi f$

<br>

#### Normal equations

$$\begin{aligned}0&=2\phi\phi^T a-2\phi f \\ \phi\phi^Ta&=\phi f\\ (<\phi_i,\phi_j>_w)a&=(<\phi,f>_w)\end{aligned}$$

当$w$是SPD，则$<\phi,f>_w$是SPD matrix

<br>

$\phi_i$代表的是$\phi$矩阵中的一列

<br>

***Example***: Approximate 

| x    | 1    | 2    | 3    | 4    |
| ---- | ---- | ---- | ---- | ---- |
| y    | 4    | 10   | 18   | 26   |

with $y=a_0+a_1x+a_2x^2$ and $w\equiv 1$

Solution:

First construct the orthogonal polynomials $\varphi_0(x),\varphi_1(x),\varphi_2(x)$

$\varphi_0(x)=1,\varphi_1(x)=x,\varphi_2(x)=x^2$

$$y=a_0\varphi_0(x)+a_1\varphi_1(x)+a_2\varphi_2(x)$$

$$\begin{aligned}(\varphi_0,\varphi_0)&=\sum_{i=1}^4 1\cdot 1=4\\ (\varphi_0,\varphi_1)&=\sum_{i=1}^4 1\cdot x_i=10\\(\varphi_0,\varphi_2)&=\sum_{i=1}^41\cdot x_i^2=30 \\(\varphi_1,\varphi_2)&=\sum_{i=1}^4x_i\cdot x_i^2=100\\(\varphi_1,\varphi_1)&=\sum_{i=1}^4x_i^2=30\\(\varphi_2,\varphi_2)&=\sum_{i=1}^4x_i^4=354\\\end{aligned}$$

$(\varphi_0,y)=\sum_{i=1}^41\cdot y_i=58\quad (\varphi_1,y)=182\quad (\varphi_0,y)=622$

<br>

$$\left[\begin{matrix}4&10&30\\10&30&100\\30&100&354\end{matrix}\right]\left[\begin{matrix}a_0\\a_1\\a_2\end{matrix}\right]=\left[\begin{matrix}58\\182\\622\end{matrix}\right]$$

解得$a_0=-\frac{3}{2},a_1=\frac{49}{10},a_2=\frac{1}{2}$

$y=P(x)=\frac{1}{2}x^2+\frac{49}{10}x-\frac{3}{2}$

但是这种做法条件数会变得非常的差

$\Vert B\Vert_\infty=484,\Vert B^{-1}\Vert=\frac{63}{4}\Rightarrow K(B)=7623$

<br>

Example:

<br>

#### Improvement

如果我们可以找到一组基函数$\{\varphi_0(x),\varphi_1(x),\cdots,\varphi_n(x) \}$是的$\varphi_i(x)$和$\varphi_j(x)$是正交的。那么normal matrix就是对角矩阵

这样可以直接解出$a$, $a_k=\frac{<\varphi_k,f>}{<\varphi_k,\varphi_k>}$

Construction of the orthogonal polynomials：

<a href="https://www.zhihu.com/question/60689540">施密特正交化</a>

`Theorem`{:.error}

The set of polynomial functions $\{\varphi_0(x),\varphi_1(x),\cdots,\varphi_n(x)\}$ defined in the following way is orthogonal on $[a,b]$ with respect to the weight function $w$.

$\varphi_0(x)=1,\varphi_1(x)=x-B_1$

$\varphi_k(x)=(x-B_k)\varphi_{k-1}(x)-C_k\varphi_{k-2}(x)$

where $B_k=\frac{(x\varphi_{k-1},\varphi_{k-1})}{(\varphi_{k-1},\varphi_{k-1})}, C_k=\frac{(x\varphi_{k-1},\varphi_{k-2})}{(\varphi_{k-2},\varphi_{k-2})}$





# 3. Chebyshev Polynomials and Economization of Power Series

general least squares approximation problem的目标找到一个多项式$P(x)$, 使得$E=(P-y,P-y)=\Vert P-y\Vert_2^2$最小

这里我们想用无穷范数。目标是

Minimize $\Vert P-y\Vert_\infty$---the minmax problem(找最大值的最小值)

<br>

更准确的表述一下，我们的任务是：

Find a polynomial $P_n(x)$ of degree $n$ such that $\Vert P_n-f\Vert_\infty$ is minimized.



`Definition`{:.warning}

If $P(x_0)-f(x_0)=\pm \Vert P-f\Vert_\infty$, $x_0$ is called a ($\pm$) **deviation point**(偏离点)

也就是$P(x)$与$f(x)$差距最大的点



1. 如果$f\in C[a,b]$ 并且$f$不是一个n阶多项式(也就是说$f$不能和一个n阶多项式一模一样)， 那么存在一个唯一的多项式$P_n(x)$使得$\Vert P_n-f\Vert_\infty$最小
2. $P_n(x)$存在，并且有+和-偏离点(否则，假设只有上偏离点，我们可以下移$P_n(x)$使得$\Vert P-f\Vert_\infty$减小，这是矛盾的)
3. ( ***Chebyshev Theorem***) $P_n(x)$最小化$\Vert P_n-f\Vert_\infty$等价于存在至少$n+2$个上下偏离点(上下交替)。也就是说存在一组点$a\leq t_1<\cdots <t_{n+2}\leq b$使得

$$P_n(t_k)-f(t_k)=\pm (-1)^k\Vert P_n-f\Vert_\infty$$

这组$\{t_k\}$叫做chebyshev alternating sequence.

($n+2$个偏离点对应$n+1$个插值点)

<img src="../../../assets/images/image-20200511104149224.png" alt="image-20200511104149224" style="zoom:30%;" />

我们的目标任务变为：

Determine the interpolating points $\{x_0,\cdots,x_n\}$ such that $P_n(x)$ minimizes the remainder

$\vert P_n(x)-f(x)\vert=\vert R_n(x)\vert =\vert \frac{f^{(n+1)}(\xi)}{(n+1)!}\Pi_{i=0}^n (x-x_i)\vert$

$\{x_0,\cdots,x_n\}$并不是事先知道的

<br>

我们的目标任务又变为：

Find $\{x_1,\cdots,x_n\}$ such that $\Vert w_n\Vert_\infty$ is minimized on $[-1,1]$ where $w_n(x)=\Pi_{i=1}^n(x-x_i)$

$w_n(x)$首项系数为1，剩余部分为$n-1$阶多项式，因此

$w_n(x)=x^n-P_{n-1}(x)$

<br>

我们的目标任务又变为：

Find a polynomial $P_{n-1}(x)$ such that $\Vert x^n-P_{n-1}(x)\Vert_\infty$ is minimized on $[-1,1]$

<br>

## Chebyshev polynomials

Consider the $n+1$ extreme values of cos$(n\theta)$ on $[0,\pi]$

$cos(n\theta)$很好的满足了上下波动的要求，但是他不是一个多项式。如何在$cos\theta$和多项式之间建立起联系呢？

<br>

令 $x=cos(\theta)$, 那么$x\in[-1,1]$

$T_n(x)=cos(n\theta)=cos(n\cdot arc\;cos\;x)$ 叫做chebyshev polynomial

<br>

$T_n(x)$取到1或者-1的点为

$x_k=cos(\frac{k}{n}\pi)\;(k=0,1,\cdots,n)$

$T_n(x)$的n个根为$x_k=cos(\frac{2k-1}{2n}\pi)\;(k=1,\cdots,n)$

<br>

写出$T_n(x)$的递推式

$T_0(x)=1,\; T_1(x)=cos(arc\;cos\;x)=x$

<br>

$T_{n+1}(x)=cos((n+1)\theta)=cos(n\theta)cos\theta-sin(n\theta)sin\theta$

$T_{n-1}(x)=cos((n+1)\theta)=cos(n\theta)cos\theta+sin(n\theta)sin\theta$

相加得

$T_{n+1}(\theta)=2cos\theta cos(n\theta)-T_{n-1}(x)$

也就是$T_{n+1}(x)=2xT_n(x)-T_{n-1}(x)$

$\Rightarrow$ $T_n(x)$是一个最高阶系数为$2^{n-1}$的多项式

<br>

联系前面: 我们的目标是

Find a polynomial $P_{n-1}(x)$ such that $\Vert x^n-P_{n-1}(x)\Vert_\infty$ is minimized on $[-1,1]$

我们取$w_n(x)=x^n-P_{n-1}(x)=\frac{T_n(x)}{2^{n-1}}$(因为$T_n(x)$最高阶系数为$2^{n-1}$, $w_n(x)$最高阶系数为1)

<br>

接下来

Find $\{x_1,\cdots,x_n\}$ such that $\Vert w_n\Vert_\infty$ is minimized on $[-1,1]$ where $w_n(x)=\Pi_{i=1}^n(x-x_i)$

我们有

$$min\Vert w_n\Vert_\infty=\Vert\frac{1}{2^{n-1}}T_n(x)\Vert_\infty=\frac{1}{2^{n-1}}$$



$\vert P_n(x)-f(x)\vert =\vert R_n(x)\vert =\vert \frac{f^{(n+1)}(\xi)}{(n+1)!}\Pi_{i=0}^n(x-x_i)\vert$

我们取$T_{n+1}(x)$的$n+1$个根作为插值点$\{x_0,x_1,\cdots,x_n\}$, 那么

$$\vert P_n(x)-f(x)\vert<\frac{M}{2^n(n+1)!}$$



<img src="../../../assets/images/image-20200511124348251.png" alt="image-20200511124348251" style="zoom:50%;" />

<br>

***Example:***

Find the best approximating polynomial of $f(x)=e^x$ on $[0,1]$ such that the absolute error is no larger than $0.5\times 10^{-4}$

* Determine n

对变量$x$做一个变换,变换到$[-1,1]$区间

$$x=\frac{a+b}{2}+\frac{b-a}{2}t=\frac{1}{2}(t+1)\Rightarrow t\in[-1,1]$$

$\vert R_n\vert\leq \vert \frac{f^{(n+1)}(\xi)}{(n+1)!}\Pi_{i=0}^n(x-x_i)\vert\leq \vert \frac{e}{(n+1)!}\Pi_{i=0}^n\frac{1}{2}(t+1-(t_i+1))\vert$

$\leq \vert \frac{e}{(n+1)!}\frac{1}{2^{(n+1)}}\Pi_{i=0}^n(t-t_i)\vert\leq \vert \frac{e}{(n+1)!}\frac{1}{2^{(n+1)}}\frac{1}{2^n} \vert $

$\because \vert R_n\vert <\frac{1}{2}\times 10^{-4}$

$\therefore n=4$

* Find the roots of $T_5(t)$

$t_0=cos\frac{\pi}{10},t_1=cos\frac{3\pi}{10},t_2=cos\frac{5\pi}{10},t_3=cos\frac{7\pi}{10},t_4=cos\frac{9\pi}{10}$

* Make a change of the variable

$x_0=\frac{1}{2}(cos\frac{\pi}{10}+1)\approx 0.98, x_1=\frac{1}{2}(cos\frac{3\pi}{10}+1)\approx 0.79$

$x_2=\frac{1}{2}(cos\frac{5\pi}{10}+1)\approx 0.50, x_3=\frac{1}{2}(cos\frac{7\pi}{10}+1)\approx 0.21$

$x_4=\frac{1}{2}(cos\frac{9\pi}{10}+1)\approx 0.02$

* Compute lagrange polynomial $L_4(x)$ with interpolating points $x_0,\cdots,x_4$



## Economization of Power Series

目标：

Given $P_n(x)\approx f(x)$, economization of power series is to **reduce the degree** of polynomial with **a minimal loss of accuracy**

<br>

考虑用一个$n-1$阶的多项式$P_{n-1}$来近似一个任意的n阶多项式

$$P_n(x)=a_nx^n+a_{n-1}x^{n-1}+\cdots+a_1x+a_0$$

$P_{n-1}$移除了$n$阶多项式$Q_n(x)$, $Q_n(x)$的$x^n$项的系数是$a_n$

$$\underset{[-1,1]}{max}\vert f(x)-P_{n-1}(x)\vert\leq \underset{[-1,1]}{max}\vert f(x)-P_n(x)\vert+\underset{[-1,1]}{max}\vert Q_n(x)\vert$$

为了使误差最小，$Q_n(x)$必须为$a_n\times \frac{T_n(x)}{2^{n-1}}$

<br>

Example: 

考虑$f(x)=e^x,\;x\in[-1,1]$的4阶泰勒多项式

$$P_4=1+x+\frac{x^2}{2}+\frac{x^3}{6}+\frac{x^4}{24}$$

他误差的upperbound为$\vert R_4(x)\vert\leq \frac{e}{5!}\vert x^5\vert\approx 0.023$

请将多项式的阶降到2

<br>

* $T_4=8x^4-8x^2+1$

$Q_4=\frac{1}{24}\times \frac{1}{2^3}T_4(x)=\frac{1}{24}(x^4-x^2+\frac{1}{8})$

$P_3=P_4-Q_4=1+x+\frac{x^2}{2}+\frac{x^3}{6}-\frac{1}{24}(-x^2+\frac{1}{8})=\frac{191}{192}+x+\frac{13}{24}x^2+\frac{1}{6}x^3$

$T_3=4x^3-3x$

* $Q_3=\frac{1}{6}\times\frac{1}{2^2}T_3(x)=\frac{1}{6}(x^3-\frac{3}{4}x)$

$P_2=P_3-Q_3=\frac{13}{24}+\frac{9}{8}x+\frac{191}{192}$

$\Vert e^2-P_2(x)\Vert_\infty\approx 0.057$

