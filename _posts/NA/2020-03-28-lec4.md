---
title: "Pivoting and Factorization for Solving Linear Systems"
tags: Numarical_Analysis
key: page-NA4





---

<!--more-->

Solve $AX=b$

# 1. Pivoting

A row interchange was needed when one of the pivot elements $a_{kk}^{(k)}$  is 0. This row interchange has the form $(E_k ) ↔ (E_p )$, where p is the smallest integer greater than k with a $a_{pk}^{(k)}  = 0$. To reduce round-off error, it is often necessary to perform row interchanges even when the pivot elements are not zero.

* If $a_{kk}^{(k)}<< a_{jk}^{(k)}$ , then the magnitude of the multiplier

$$m_{jk}=\frac{a_{jk}^{(k)}}{a_{kk}^{(k)}}$$

will be much larger than 1.

Round-off error introduced in the computation of one of the terms $a_{kl}^{(k)}$ is multiplied by $m_{jk}$ when computing $a_{jl}^{k+1}$, which compounds the original error.

* Also, when performing the backward substitution for

$$x_k=\frac{a_{k,n+1}^{(k)}-\sum_{j=k+1}^n a_{kj}^{(k)}}{a_{kk}^{(k)}}$$

with a small value of $a_{kk}^{(k)}$ ,any error in the numerator can be dramatically increased because of the division by $a_{kk}^{(k)}$.

<br>

See some examples:

$$\left[\begin{matrix}0.03 & 59.14\\5.291&-6.130\end{matrix}\right]\left[\begin{matrix}x_1\\x_2\end{matrix}\right]=\left[\begin{matrix}59.17\\46.78\end{matrix}\right]$$

The exact solution is $x_1=10, x_2=1$

Using 4-digit arithmetic Gauss Elimination

The first pivot element, $a_{11}^{(1)}=0.003$, is small, and its associated multiplier

$$m_{21}=\frac{5.291}{0.003}=1763.6\bar{6}\approx 1764$$

Performing $(E_2-m_{21}E_1)\rightarrow E_2$

$$\left[\begin{matrix}0.03 & 59.14\\0&-104300\end{matrix}\right]\left[\begin{matrix}x_1\\x_2\end{matrix}\right]=\left[\begin{matrix}59.17\\-104400\end{matrix}\right]$$

But the exact system is:

$$\left[\begin{matrix}0.03 & 59.14\\0&-104309.37\bar{6}\end{matrix}\right]\left[\begin{matrix}x_1\\x_2\end{matrix}\right]=\left[\begin{matrix}59.17\\-104309.37\bar{6}\end{matrix}\right]$$

The disparity in the magnitudes of $m_{21}a_{13}$ and $a_{23}$ has introduced round-off error, but the round-off error has not yet been propagated. Backward substitution yields

$$x_2\approx 1.001$$

which is a close approximation to the actual value, $x_2 = 1.000$. However, because of the small pivot $a_{11}=0.003$, However

$$x_1\approx\frac{59.17-59.14\times 1.001}{0.003}=-10$$

误差：$m_{21}$有误差，$x_2=1.001$不准确，回带的时候又被极度放大

<br>

### A. Partial pivoting:

$$m_{21}=\frac{a_{21}^{(1)}}{a_{11}^{(1)}}=\frac{5.291}{0.003}$$

This problem arises when the pivot element $a_{kk}^{(k)}$ is small relative to the entries $a_{ij}^{(k)}$ , for $k\leq i\leq n$ and $k\leq j\leq n$.

Switch row p, k for large pivoting element: 比如第一行和第二行进行交换，那么第一行第一列的pivot会编程第二行第一列的pivot。在这里我们从第k行往下看这列最大的元素所在行为p, 将第k行与第p行进行交换，那么我们可以得到相对较大的pivot的系数

$$\vert a_{pk}^{(k)}\vert=\underset{k\leq i\leq n}{max}\vert a_{ik}^{(k)}\vert$$

<br>

For this example

$$\left[\begin{matrix}0.03 & 59.14\\5.291&-6.130\end{matrix}\right]\left[\begin{matrix}x_1\\x_2\end{matrix}\right]=\left[\begin{matrix}59.17\\46.78\end{matrix}\right]$$

$max\{\vert a_{11}^{(1)}\vert,\vert a_{21}^{(1)}\vert\}=max\{0.003, 5.291\}=5.291=\vert a_{21}^{(1)}\vert$

So, exchange row 1 and row 2

$$\left[\begin{matrix}5.291&-6.130\\0.03 & 59.14\end{matrix}\right]\left[\begin{matrix}x_1\\x_2\end{matrix}\right]=\left[\begin{matrix}46.78\\59.17\end{matrix}\right]$$

The multiplier for this system is 

$$m_{21}=\frac{a_{21}^{(1)}}{a_{11}^{(1)}}=0.0005670$$

and the operation $(E_2-m_{21}E_1)\rightarrow (E_2)$ reduces the system to

$$\left[\begin{matrix}5.291&-6.130\\0 & 59.14\end{matrix}\right]\left[\begin{matrix}x_1\\x_2\end{matrix}\right]=\left[\begin{matrix}46.78\\59.14\end{matrix}\right]$$

Solutions: $x_1=10.00,x_2=1.000$

<br>

`Algorithm`{:.error}

Notation $a(NROW(i),j)=a_{NROW_i,j}$

**INPUT** number of unknowns and equations n; augmented matrix $A=[a_{ij}]$, where i ≤ n and 1 ≤ j ≤ n + 1.

**OUTPUT** solution $x_1 , x_2 , . . . , x_n$ or message that the linear system has no unique solution.

**Step 1** For $i = 1, . . . , n$ set NROW(i)=i. (Initialize row pointer)

**Step 2** For $i = 1, . . . , n − 1$ do Steps 3–6. (Elimination process.)

&emsp;**Step 3** Let p be the smallest integer with i ≤ p ≤ n and $\vert a(NROW(p),i)\vert=max_{i\leq j\leq n}\vert a(NROW(j),i)\vert$

&emsp;**Step 4** If $a(NROW(p),i)=0$ then OUTPUT ('no unique solution exists'); 

&emsp;&emsp;&emsp;&emsp;STOP.

&emsp;//Row exchange

&emsp;**Step 5** If $NROW(i)\not= NROW(p)$  then set $NCOPY=NROW(i); NROW(i)=NROW(p),NROW(p)=NCOPY.$

&emsp;//进行消元

&emsp;**Step 4** For j = i + 1, . . . , n do Steps 7 and 8.

&emsp;&emsp;**Step 7** Set $m(NROW(j),i) = a(NROW(j),i)/a(NROW(i),i)$ .

&emsp;&emsp;**Step 8** Perform $(E_{NROW(j)} − m(NROW(j),i)\cdot E_{NROW(i)} ) → (E_{NROW(j)} )$;

**Step 9** If $a(NROW(n),n)=0$ then OUTPUT('no unique solution exists');

&emsp;&emsp;&emsp;&emsp;STOP.

//回带

**Step 10** Set $x_n=\frac{a(NROW(n),n+1)}{a(NROW(n),n)}$ (Start backward substitution)

**Step 11** For $i=n-1,\cdots,1$  set $x_i=\frac{a(NROW(i),n+1)-\sum_{j=i+1}^{n}a(NROW(i),j)\cdot x_j}{a(NROW(i),i)}$

**Step 12** OUTPUT($x_1,\cdots,x_n$) (Procedure completed successfully.)

&emsp;&emsp;&emsp;&emsp;STOP.



<br>

Is that enough? Of course NOT!

See this problem!

$$\left[\begin{matrix}30 & 591400\\5.291&-6.130\end{matrix}\right]\left[\begin{matrix}x_1\\x_2\end{matrix}\right]=\left[\begin{matrix}591700\\46.78\end{matrix}\right]$$

After partial pivoting

$$m_{21}=9.1764$$

$x_2\approx 1.001, x_1\approx\frac{591700-591400\times 1.001}{30}=-10$

虽然这里没有除以很小的数，但是1.001乘了很大的数，因此我们还要考虑$\frac{591400}{30}$这一项的大小

<br>

### B. Scaled Partial Pivoting(scaled-column pivoting): Largest relative to the entries in itw row.

&emsp;Step1: Define a scale factor $s_i$ for each row as $$s_i=\underset{1\leq j\leq n}{max}\vert a_{ij}\vert$$,  $s_i$是第i行最大的元素

&emsp; Step2: Determine the smallest $p\geq k$ such that $$\frac{\vert a_{pk}^{(k)}\vert}{s_p}=\underset{k\leq i\leq n}{max}\frac{\vert a_{ik}^{(k)}\vert}{s_i}$$  and interchange the pth and the kth rows. 对行做遍历，计算这一行pivot的系数和$s_i$的比值，来观察相对大小,然后进行行交换

> Note:
>
> &emsp;The scaled factors $s_i$ must be computed ***only once***, otherwise this method would be too slow.

<br>

`Algorithm`{:.error}

The only steps in this algorithm that differ from above Algorithm are:

**Step 1** For $i = 1, . . . , n$ set $s_i=max_{1\leq j\leq n}\vert a_{ij}\vert$; 

&emsp;&emsp;&emsp;&emsp;&emsp;If $s_i=0$ then OUTPUT('no unique solution exists');

&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;STOP.

&emsp;&emsp;&emsp;&emsp;&emsp;set NROW(i)=i. (Initialize row pointer)

**Step 2** For $i = 1, . . . , n − 1$ do Steps 3–6. (Elimination process.)

&emsp;**Step 3** Let p be the smallest integer with i ≤ p ≤ n and $\frac{\vert a(NROW(p),i)\vert}{s(NROW(p))}=max_{i\leq j\leq n}\frac{\vert a(NROW(j),i)\vert}{s(NROW(j))}$

<br>

Example

Solve the linear system using three-digit rounding arithmetic.

$$\begin{aligned}2.11x_1-4.21x_2+0.921x_3&=2.01\\ 4.01x_1+10.2x_2-1.12x_3&=-3.09\\1.09x_1+0.987x_2+0.823x_3&=4.21\end{aligned}$$

We have $s_1=4.21,s_2=10.2,s_3=1.09$

So, $\frac{\vert a_{11}\vert}{s_1}=\frac{2.11}{4.21}=0.501$, $\frac{\vert a_{21}\vert}{s_1}=\frac{4.01}{10.2}=0.393$, $\frac{\vert a_{31}\vert}{s_3}=\frac{1.09}{1.09}=1$

因此交换第三行和第一行,得到

$$\left[\begin{matrix}1.09&0.987&0.832&4.21\\4.01&10.2&-1.12&-3.09\\2.11&-4.21&0.921&2.01\end{matrix}\right]$$

消元后得到

$$\left[\begin{matrix}1.09&0.987&0.832&4.21\\0&6.57&-4.18&-18.6\\0&-6.12&-0.689&-6.16\end{matrix}\right]$$

$$\frac{\vert a_{22}\vert}{s_2}=\frac{6.57}{10.2}=0.644$$ and $\frac{vert a_{32}\vert}{s_3}=\frac{6.12}{4.21}=1.45$, 注意这里 $s_2,s_3$并没有重新计算

因此交换第二行和第三行

$$\left[\begin{matrix}1.09&0.987&0.832&4.21\\0&-6.12&-0.689&-6.16\\0&6.57&-4.18&-18.6\end{matrix}\right]$$

消元后得到

$$\left[\begin{matrix}1.09&0.987&0.832&4.21\\0&-6.12&-0.689&-6.16\\0&0&-4.92&-25.2\end{matrix}\right]$$

最后解得

$$\left[\begin{matrix}x_1\\x_2\\x_3\end{matrix}\right]=\left[\begin{matrix}-0.436\\0.430\\5.12\end{matrix}\right]$$

<br>

当最理想的是进行行列交换，行交换会减小$m_{21}$的误差，列交换会减小$x_1$的误差

### C. Complete Pivoting(or maximal pivoting)

Search all the entries $a_{ij}$ for $i,j=k,\cdots,n$, to find the entry with the largest magnitude. Both row and column interchanges are performed to bring this entry to the pivot position.

遍历整个矩阵去寻找最大的数，然后进行行列交换，计算量相当大

<br>

trick: 0不能做分母，无穷大的误差放大。碰到很小的数也是同样的道理，解丧失了区分度





### D. Amount of Computation

* Partial Pivoting: Requires about $O(n^2)$ additional comparisons.
* Scaled Partial Pivoting: Requires about $O(n^2)$ additional comparisons and $O(n^2)$ divisions.[n行，每行在选择时要计算笔值并且进行比较$n^2$]
* Complete Pivoting: Requires about $O(\frac{n^3}{3})$ additional comparisons.[n行，每行在选择时做$n^2$次比较]

<br>

<br>

# 2. Matrix Factorization



Matrix Form of Gaussian Elimination

&emsp;Step1: $m_{i1}=\frac{a_{i1}}{a_{11}}\quad (a_{11}\not=0)$

<img src="../../../assets/images/image-20200322212140210.png" alt="image-20200322212140210" style="zoom:50%;" />

所有L都是下三角矩阵。一个很好的性质是下三角矩阵在乘法操作下依然是下三角矩阵。它的inverse依然是下三角矩阵

<img src="../../../assets/images/image-20200322212529061.png" alt="image-20200322212529061" style="zoom:50%;" />

<a href="https://blog.csdn.net/wo94chunjie/article/details/103859745">LU分解有什么意义1</a>

<a href="https://www.zhihu.com/question/52451868?sort=created">LU分解有什么意义2</a>

$Ax=b$

$A=LU$

* First let $y=UX$ and solve the lower triangular system $Ly = b$ for y. Since L is triangular, determining y from this equation requires only $O(n^2)$ operations.
* Once y is known, the upper triangular system $Ux = y$ requires only an additional $O(n^2)$ operations to determine the solution x.

<br>

Theorem: If Gaussian elimination can be performed on the linear system $A\vec{x}=\vec{b}$ **withour row interchanges**, then the matrix A can be factored into the product of a lower-triangular matrix L and an upper-triangular matrix U.

If L has to be unitary(对角线全1)， then the factorization is unique

Proof(for uniqueness):

If the factorization is NOT unique, then there exist $L_1,U_1,L_2,U_2$ such that 

$$A=L_1U_1=L_2U_2$$

$$U_1U_2^{-1}=L_1^{-1}L_2U_2U_2^{-1}=L_1^{-1}L_2$$

$U_1U_2^{-1}$是上三角矩阵, $L_1^{-1}L_2$是下三角矩阵且对角线元素都是1. 因此

$$U_1U_2^{-1}=L_1^{-1}L_2U_2U_2^{-1}=L_1^{-1}L_2=I$$

<br>

# 3. Special Types of Matrices

### A.Strictly Diagonally Dominant Matrix

对角线元素比同一行其他元素加起来还大

$$\vert a_{ii}\vert>\underset{j=1,j\not=i}{\overset{n}{\sum}} \vert a_{ij}\vert\quad for\;each\; i=1,\cdots,n$$

Theorem: A strictly diagonally dominant matrix is <u>nonsingular</u>. Morever, Gaussian elimination can be performed <u>without row or column interchanges</u>, and the computations will be <u>stable</u> with respect to the growth of roundoff errors.

> Proof:
>
> We first use proof by contradiction to show that A is nonsingular.
>
> Consider $Ax=0$, and suppose that a nonzero solution $\mathbf{x}=(x_i)$ to this system exists. Let k be an index for which
>
> $$0<\vert x_k\vert =\underset{1\leq j\leq n}{max}\vert x_j\vert$$
>
> Because $\sum_{j=1}^n a_{ij}x_j=0$ for each $i=1,2,\cdots,n$, we have, when i = k
>
> $$a_{kk}x_k=-\underset{j=1,j\not= k}{\overset{n}\sum}a_{kj}x_j$$
>
> From the triangle inequality we have
>
> $$\vert a_{kk}\vert\vert x_k\vert \leq \underset{j=1,j\not= k}{\overset{n}\sum}\vert a_{kj}\vert \vert x_j\vert, so\quad \vert a_{kk}\vert\leq \underset{j=1,j\not=k}{\overset{n} \sum}\vert a_{kj}\vert\frac{\vert x_j\vert}{\vert x_k\vert}\leq \underset{j=1,j\not=k}{\overset{n} \sum}\vert a_{kj}\vert$$
>
> However, for strictly diagonally dominant matrix, $$\vert a_{ii}\vert>\underset{j=1,j\not=i}{\overset{n}{\sum}} \vert a_{ij}\vert\quad for\;each\; i=1,\cdots,n$$,
>
> Contradiction!!!!!!
>
> Consequently, the only solution $Ax=0$ is $x=0$. Then we can deduct taht A si nonsigular matrix.
>
> <br>
>
> To prove that Gaussian elimination can be performed without row interchanges, we show taht each of the matrices $A^{(2)},A^{(3)},\cdots,A^{(n)}$ generateed by the Gaussian elimination process is diagnolly dominant.
>
> Since A is strictly diagonally dominant, $a_{11}\not= 0$ and $A^{(2)}$ can be formed. Thus for each $i=2,3,\cdots,n$
>
> $a_{ij}^{(2)}=a_{ij}^{(1)}-\frac{a_{1j}^{(1)}a_{i1}^{(1)}}{a_{11}^{(1)}}, for\; 2\leq j\leq n$
>
> First, $a_{i1}^{(2)}=0$. The triangle inequality implies that
>
> $$\underset{j=2,j\not= i}{\overset{n}\sum}\vert a_{ij}^{(2)}\vert=\underset{j=2,j\not= i}{\overset{n}\sum}\vert a_{ij}^{(1)}-\frac{a_{1j}^{(1)}a_{i1}^{(1)}}{a_{11}^{(1)}}\vert \leq \underset{j=2,j\not= i}{\overset{n}\sum}\vert a_{ij}^{(1)}\vert +\underset{j=2,j\not= i}{\overset{n}\sum}\vert \frac{a_{1j}^{(1)}a_{i1}^{(1)}}{a_{11}^{(1)}}\vert$$
>
> But since A is strictly diagonally dominant
>
> $$\underset{j=2,j\not= i}{\overset{n}\sum}\vert a_{ij}^{(1)}\vert<\vert a_{ii}^{(1)}\vert-\vert a_{i1}^{(1)}\vert \quad and\quad \underset{j=2,j\not= i}{\overset{n}\sum}\vert a_{1j}^{(1)}\vert<\vert a_{11}^{(1)}\vert-\vert a_{1i}^{(1)}\vert$$
>
> so
>
> $\underset{j=2,j\not= i}{\overset{n}\sum}\vert a_{ij}^{(2)}\vert \leq \underset{j=2,j\not= i}{\overset{n}\sum}\vert a_{ij}^{(1)}\vert +\underset{j=2,j\not= i}{\overset{n}\sum}\vert \frac{a_{1j}^{(1)}a_{i1}^{(1)}}{a_{11}^{(1)}}\vert$
>
> $\leq  \vert a_{ii}^{(1)}\vert-\vert a_{i1}^{(1)}\vert+\frac{\vert a_{i1}^{(1)}\vert}{\vert a_{11}^{(1)}\vert}(\vert a_{11}^{(1)}\vert -\vert a_{1i}^{(1)}\vert)=\vert a_{ii}^{(1)}\vert -\frac{\vert a_{i1}^{(1)}\vert\vert a_{1i}^{(1)}\vert}{\vert a_{11}^{(1)}\vert}$
>
> The triangle inequality also implies that
>
> $$\vert a_{ii}^{(1)}\vert -\frac{\vert a_{i1}^{(1)}\vert\vert a_{1i}^{(1)}\vert}{\vert a_{11}^{(1)}\vert}\leq \vert\;\vert a_{ii}^{(1)}\vert -\frac{\vert a_{i1}^{(1)}\vert\vert a_{1i}^{(1)}\vert}{\vert a_{11}^{(1)}\vert}\vert=\vert a_{ii}^{(2)}\vert$$
>
> which gives
>
> $$\underset{j=2,j\not= i}{\overset{n}\sum}\vert a_{ij}^{(2)}\vert\leq \vert a_{ii}^{(2)}\vert$$
>
> This establishes the strict diagonal dominance for rows 2, . . . , n. But the ﬁrst row of $A^{(2)}$ and A are the same, so  $A^{(2)}$ is strictly diagonally dominant.
>
> This process is continued inductively until the upper-triangular and strictly diagonally dominant $A^{(n)}$ is obtained. 
>
> This implies that ***all the diagonal elements are nonzero***, so Gaussian elimination can be performed without row interchanges.



> 注意：
>
> 并不是所有nonsigular矩阵不需要进行行列交换来进行高斯消元。
>
> 考虑
>
> $$\left[\begin{matrix} 1 & 0 & 0\\ 0&1&0\\0&0&1\end{matrix}\right]$$
>
> $$A=\left[\begin{matrix} 0 & 1 & 0\\ 1&0&0\\0&0&1\end{matrix}\right]$$, 这是一个非奇异矩阵，因为A等于I乘上一个基本矩阵。但是在高斯消元的时候需要进行行交换。
>
> 在高斯消元时进行行列交换，我们可以看到，是为了提高精度。但是反pivoting会增大误差

<br>

### 3. Choleski's Method for Positive Definite Matrix

symmetric positive definite: SPD对称正定矩阵

Definition: A matrix A is <u>positive definite</u> if it is <u>symmetric</u> and if $\vec{x}^tA\vec{x}>0$ for every n-dimensional vector $\vec{x}\not=0$.

$x^tAx=[x_1,x_2,\cdots,x_n]\left[\begin{matrix}a_{11}&a_{12}&\cdots&a_{1n}\\ a_{21}&a_{22}&\cdots &a_{2n}\\ \vdots &\vdots & &\vdots\\ a_{n1}&a_{n2}&\cdots &a_{nn}\end{matrix}\right]\left[\begin{matrix}x_1\\x_2\\ \vdots\\x_n\end{matrix}\right]$

$=[x_1,x_2,\cdots,x_n]\left[\begin{matrix}\sum_{j=1}^n a_{1j}x_j\\ \sum_{j=1}^n a_{2j}x_j\\ \vdots\\\sum_{j=1}^n a_{nj}x_j\end{matrix}\right]=[\sum_{i=1}^n\sum_{j=1}^n a_{ij}x_ix_j]$

<br>

Review: A is positive definite

* $A^{-1}$ is positive definite as well, and $a_{ii}>0$
* $max\vert a_{ij}\vert\leq max\vert a_{kk}\vert$; $(a_{ij})^2<a_{ii}a_{jj}\;for\;each\;i\not=j$

* Each of A's leading principal submatrices $A_k$(顺序主子式) has a positive determinant.

<img src="../../../assets/images/image-20200322215946660.png" alt="image-20200322215946660" style="zoom:50%;" />

Example:

Determine the Cholesky $LL^t$ factorization of the positive deﬁnite matrix

$$A=\left[\begin{matrix}4&-1&1\\-1&4.25&2.75\\1&2.75&3.5\end{matrix}\right]$$

Solution:

$$A=\left[\begin{matrix}a_{11}&a_{21}&a_{31}\\a_{21}&a_{22}&a_{23}\\a_{31}&a_{32}&a_{33}\end{matrix}\right]=\left[\begin{matrix}l_{11}&0&0\\l_{21}&l_{22}&0\\l_{31}&l_{32}&l_{33}\end{matrix}\right]\left[\begin{matrix}l_{11}&l_{21}&l_{31}\\0&l_{22}&l_{32}\\0&0&l_{33}\end{matrix}\right]$$

$$=\left[\begin{matrix}l_{11}^2 &l_{11}l_{21}&l_{11}l_{31}\\ l_{11}l_{21}&l_{21}^2+l_{22}^2&l_{21}l_{31}+l_{22}l_{32}\\l_{11}l_{31}&l_{21}l_{31}+l_{22}l_{32}&l_{31}^2+l_{32}^2+l_{33}^2\end{matrix}\right]$$

Thus

$a_{11}: 4=l_{11}^2\Rightarrow l_{11}=2\quad a_{21}: -1=l_{11}l_{21}\Rightarrow l_{21}=-0.5 $

$a_{31}: 1=l_{11}l_{31}\Rightarrow l_{31}=0.5\quad a_{22}: 4.25=l_{21}^2+l_{22}^2\Rightarrow l_{22}=2 $

$a_{32}: 2.75=l_{21}l_{31}+l_{22}l_{32}\Rightarrow l_{32}=1.5\quad a_{33}: 3.5=l_{31}^2+l_{32}^2+l_{33}^2\Rightarrow l_{33}=1 $

$$A=LL^t=\left[\begin{matrix}2&0&0\\-0.5&2&0\\0.5&1.5&1\end{matrix}\right]\left[\begin{matrix}2&-0.5&0.5\\0&2&1.5\\0&0&1\end{matrix}\right]$$

### C. Crout Reduction for Tridiagonal Linear System

<img src="../../../assets/images/image-20200322220222715.png" alt="image-20200322220222715" style="zoom:50%;" />



Example

Determine the Crout factorization of the symmetric tridiagonal matrix

$$\left[\begin{matrix}2&-1&0&0\\-1&2&-1&0\\0&-1&2&-1\\0&0&-1&2\end{matrix}\right]$$

and use this factorization to solve the linear system

$$\left[\begin{matrix}2&-1&0&0\\-1&2&-1&0\\0&-1&2&-1\\0&0&-1&2\end{matrix}\right]\left[\begin{matrix}x_1\\x_2\\x_3\\x_4 \end{matrix}\right]=\left[\begin{matrix}1\\0\\0\\1\end{matrix}\right]$$



Solution:

$$A=\left[\begin{matrix}a_{11}&a_{12}&0&0\\a_{21}&a_{22}&a_{23}&0\\0&a_{32}&a_{33}&a_{34}\\0&0&a_{43}&a_{44}\end{matrix}\right]=\left[\begin{matrix}l_{11}&0&0&0\\ l_{21}&l_{22}&0&0\\ 0&l_{32}& l_{33}&0\\ 0&0&l_{43}&l_{44}\end{matrix}\right]  \left[\begin{matrix}1&u_{12}&0&0\\0&1&u_{23}&0\\0&0&1&u_{34}\\0&0&0&1\end{matrix}\right]$$

$$=\left[\begin{matrix}l_{11}&l_{11}u_{12}&0&0\\ l_{21}& l_{22}+l_{21}u_{12}& l_{22}u_{23}&0\\ 0&l_{32}&l_{33}+l_{32}u_{23}&l_{33}u_{34}\\0&0&l_{43}&l_{44}+l_{43}u_{34}\end{matrix}\right]$$

Thus

$a_{11}:2=l_{11}\Rightarrow l_{11}=2\quad\quad a_{12}:-1=l_{11}u_{12}\Rightarrow u_{12}=-\frac{1}{2}$

$a_{21}:-1=l_{21}\Rightarrow l_{21}=-1\quad\quad a_{22}:2=l_{22}+l_{21}u_{12}\Rightarrow l_{22}=-\frac{3}{2}$

$a_{23}:-1=l_{22}u_{23}\Rightarrow u_{23}=-\frac{2}{3}\quad\quad a_{32}:-1=l_{32}\Rightarrow l_{32}=-1$

This gives the Crout factorization

$$A=\left[\begin{matrix}2&-1&0&0\\-1&2&-1&0\\0&-1&2&-1\\0&0&-1&2\end{matrix}\right]=\left[\begin{matrix}2&0&0&0\\-1&\frac{3}{2}&0&0\\0&-1&\frac{4}{3}&0\\0&0&-1&\frac{5}{4}\end{matrix}\right]\left[\begin{matrix}1&-\frac{1}{2} &0&0\\ 0&1&-\frac{2}{3}&0\\0&0&1&-\frac{3}{4}\\0&0&0&1 \end{matrix}\right]=LU$$

Solving the system

$$Lz=\left[\begin{matrix}2&0&0&0\\-1&\frac{3}{2}&0&0\\0&-1&\frac{4}{3}&0\\0&0&-1&\frac{5}{4}\end{matrix}\right]\left[\begin{matrix}z_1\\z_2\\z_3\\z_4\end{matrix}\right]=\left[\begin{matrix}1\\0\\0\\1\end{matrix}\right]$$

gives 

$$\left[\begin{matrix}z_1\\z_2\\z_3\\z_4\end{matrix}\right]=\left[\begin{matrix}\frac{1}{2}\\\frac{1}{3}\\\frac{1}{4}\\ 1\end{matrix}\right]$$

and then solving

$$Ux=\left[\begin{matrix}1&-\frac{1}{2} &0&0\\ 0&1&-\frac{2}{3}&0\\0&0&1&-\frac{3}{4}\\0&0&0&1 \end{matrix}\right]\left[\begin{matrix}x_1\\x_2\\x_3\\x_4\end{matrix}\right]=\left[\begin{matrix}\frac{1}{2}\\\frac{1}{3}\\\frac{1}{4}\\ 1\end{matrix}\right]$$

gives 

$$\left[\begin{matrix}x_1\\x_2\\x_3\\x_4\end{matrix}\right]=\left[\begin{matrix}1\\1\\1\\ 1\end{matrix}\right]$$

