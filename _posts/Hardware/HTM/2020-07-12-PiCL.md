---
title: "PiCL"
tags: HTM hardware
key: page-PiCL


---

<!--more-->

# PiCL: a Software-Transparent, Persistent Cache Log for Nonvolatile Main Memory

PiCL (procounced pickle)

<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8574565">MICRO 2018: paper</a>

#### Background

**Previous two problems**

* cache flushes are mandatory at each epoch. But the cache flush latency dominates both the commit and execution time leading to high overhead. Cache flushes are often synchronous. They stop the whole system until completely finished. (注意这个点, cache flush会使整个系统停滞, 而且平均来说，从cache写回2MB的dirty data到DRAM需要1ms, 或者说10%的10ms checkpoint时间)
* Redo and undo logging add significantly more random accesses to the NVM storage. Because NVMs have random access performance more than 10× worse than conventional DRAM, these logging patterns are costly.



#### PiCL对一些概念的解释

* **Epoch-based checkpointing**

<img src="../../../../assets/images/image-20200711210011208.png" alt="image-20200711210011208" style="zoom:60%;" />



* NVM中transaction和databse中的transaction的区别

NVM中的commit和database中的commit是有区别的: NVM中commit了只能保证atomicity, consistency, isolation, 但是并不能保证durability。

事实上，在NVM里面，事务执行的阶段应该做如下划分，注意在committed epoch后面应该有一个persisted epoch.

<img src="../../../../assets/images/image-20200711212949596.png" alt="image-20200711212949596" style="zoom:67%;" />



* redo, undo存在的问题

> * redo buffer are not scalable to large multi-core systems
>   * 当write set变大后，很容易buffer overflow
>   * need a translation table 
> * undo logging has poor data spatial locality
>
> 从下图来看：这里所解释redo logging的方法很类似shadow paging, cache evict的new value先更新到redo buffer中，需要一个translation table来指明new value存在redo buffer中的地址，这和DHTM中使用的redo logging还是有区别的。而undo logging是在memory中做的，从memory中获取旧值，这也和我的认知有差异。

<img src="../../../../assets/images/image-20200712192658458.png" alt="image-20200712192658458" style="zoom:75%;" />

#### 主要设计思想与贡献

* Multi-undo logging
* cache-driven logging
* asynchronous cache-scan
  * take the cache flushes off the critical path
  * coalesce undo writes to better match the page-based performance characteristics of NVMs

<br>

**cache driven logging and multi-undo logging**

给每一个cacheline 增加一个epoch ID(EID) 数据，当cache evict到low level cache时，如果发现cacheline的EID不一样，则就把low level的数据作为undo data, 如果EID一样就不需要log。通过这种方式，基本上每个数据只生成一个undo log。

如果每次生成log都需要写memory的话很费IO, 为了undo data写回使用更少的IO次数，采用group commit的方式。增加一个on-chip undo buffer, 生成的undo data发送给undo buffer。这样会导致一个问题: 有可能new value evict出cache, 但是undo log还在undo buffer中。因此增加一个bloom filter，当数据要被evict出cache时，先判断undo buffer有没有对应的undo data, 如果有则先flush buffer。

<br>

**asynchronous cache-scan**

因为数据和log都要通过cache到达memory, 因此需要flush来强制这些写回memory。

synchronous flush会使整个flush过程占据critical path。因此PiCL提出Asynchronous Cache Scanning (ACS)将flush过程冲critical path中抽出来。肉眼可见效率变高。这个实现起来比较简单，只要根据一定的频率去scan LLC的EID, 如果是targeted EID并且是dirty data, 就flush回去并且将dirty置为clean。

<img src="../../../../assets/images/image-20200712205335828.png" alt="image-20200712205335828" style="zoom:70%;" />



#### 其他文章对PiCL的评价

tbc...

慢慢读吧