---
layout: article
title: Shannon Theory
tags: Cryptography
key: page-cryptLec3
article_header:
  type: overlay
  theme: dark
  background_color: '#203028'
  background_image:
    gradient: 'linear-gradient(135deg, rgba(34, 139, 87 , .4), rgba(139, 34, 139, .4))'
  background_image:
    src: https://miaochenlu.github.io/picture/EDD6F47E7DDE25D08BB6320511A6F0BD.png





---

<!--more-->

# 1. Introduction

### security criteria

* computational security：破解算法至少需要n步操作，N是一个确定的非常大的数---computatioal
* provable security: 如果cryptosystem可以被破解，就相当于可以解决一个已知的难问题(NP-complete?)---reduction归约
* unconditional security: 就算有无穷的计算资源，也不可能破解

# 2. Elementary Probability Theory

`Definition`{:.warning}

A discrete random variable, say $\mathbf{X}$, consists of a finite set $S$ and a probability distribution defined on X. The probability that the random variable X takes on the value x is denoted $Pr[\mathbf{X}=x]$; sometimes we will abbreviate this to $Pr[x]$ if the random variable $\mathbf{X}$ is fixed. It must be the case that $0\leq Pr[x]$ for all $x\in X$, and 

$$\sum_{x\in X}Pr[x]=1$$

<br>

Suppose we have a random variable $\mathbf{X}$ defined on X, and $E\subseteq X$. The brobability that $\mathbf{X}$ takes on a value in the subset E is computed to be

$$Pr[x\in E]=\sum_{x\in E}Pr[x]$$

The subset E of often called an **event**

<br>

`Definition`{:.warning}

* Joint probability distribution of $(\mathbf{X},X),(\mathbf{Y},Y)$ is a function $X\times Y\mapsto \mathbb{R}$, $(x,y)\mapsto Pr(X=x,Y=y)$

* conditional probability $Pr(x\vert y)$
* independent: $Pr(\mathbf{X}=x,\mathbf{Y}=y)=Pr(x)Pr(y)$

<br>

`Bayes' Theorem`{:.error}

if $Pr[y]>0$, then $Pr[x\vert y]=\frac{Pr[x]Pr[y\vert x]}{Pr[y]}$

<br>

# 3. Perfect Secrecy

Hypothesis: a **particular ke**y is used for **one encryption**.一次一密

Suppose the information(plaintext) comes in a stream, $\cdots x_3x_2x_1$, 

* 对于明文的第一项$x_1$, 我们根据一定的概率分布生成一个key $K_1$ , 并且用他来加密$x_1$, 得到$y_1=e_{K_1}(x_1)$
* for the 2nd plaintext $x_2$, generate a key $K_2$ by the same rule(independent of $K_1$), and use it to encrypt $x_2$, $y_2=e_{K_2}(x_2)$
* 对于明文的第二项$x_2$ , 我们根据一定的概率分布生成一个key $K_2$(与$K_1$独立) , 并且用他来加密$x_2$, 得到$y_2=e_{K_2}(x_2)$

<br>

KNOWN: 对于明文和keyspace我们分别有确定的概率分布。我们用x(resp k)来代表在明文上的离散随机变量(resp. keyspace) 

e.g. $\mathscr{P}=\mathscr{C}=\mathbb{Z}_{26}$,

plaintext: $$p:\mathbb{Z}_{26}\mapsto \mathbb{R}_{\geq 0}, ( i\mapsto p_i$$）

($p_i$ is the frequency in a meaningful English text))

key: $$p:\mathbb{Z}_{26}\mapsto \mathbb{R}_{\geq 0} , (  i\mapsto \frac{1}{26})$$

$Pr[\mathbf{X}=i]=p_i,$ random variable for plaintext

$Pr[k=i]=\frac{1}{26}$, random variable for the key

<br>

Let $\mathbf{Y}$ be  the random variable corresponding to the ciphertext.

(1). 接下来我们要确定 $Pr[y]$. 我们需要一个额外的假设: (H) x和k是相互独立的变量

定义 $c(k)=\{e_k(x):x\in P\;for\;each\; k\in K\}$

$Pr[y]=\underset{x\in P,k\in K,y=e_K(x)}{\sum}Pr[\mathbf{X}=x,\mathbf{K}=k]=\underset{\mathbf{K}\in K, y\in c(K)}{\sum} Pr[\mathbf{X}=d_K(y)]Pr[\mathbf{K}=k]$

e.g. (shift cipher) $c(K)=\mathbb{Z}_{26}$

$Pr[y]=\sum_{k=0}^{25}Pr[\mathbf{X}=y-k]Pr[\mathbf{K}=k]=\frac{1}{26}\sum_{k=0}^{25}Pr[\mathbf{X}=k]=\frac{1}{26}$

(2). 接下来我们在ciphertext only attack的情况下计算 $Pr[\mathbf{X}=x\vert \mathbf{Y}=y]$ (同样假设一次一密)。 We decipher y to the x with $Pr[\mathbf{X}=x\vert \mathbf{Y}=y]$  max(given y) (这个最大概率对应的x表示密文为y的情况下最有可能的明文x)

$Pr[\mathbf{Y}=y\vert \mathbf{X}=x]=\sum_{k:y=e_k(x)} Pr[\mathbf{K}=k]$

$Pr[\mathbf{X}=x\vert \mathbf{Y}=y]=\frac{Pr[\mathbf{Y}=y\vert \mathbf{X}=x]\cdot Pr[\mathbf{X}=x]}{Pr[\mathbf{Y}=y]}$ 

在这个例子中

$Pr[\mathbf{Y}=y\vert \mathbf{X}=x]=\sum_{y=x+k}Pr[\mathbf{K}=k]=Pr[\mathbf{K=y-x}]=\frac{1}{26}$

$Pr[\mathbf{X}=x\vert \mathbf{Y}=y]=\frac{Pr[\mathbf{Y}=y\vert \mathbf{X}=x]\cdot Pr[\mathbf{X}=x]}{Pr[\mathbf{Y}=y]}=Pr[\mathbf{X}=x]$

在我们的分析中

* 如果我们对ciphertext (y) 一无所知, 我们猜测最有可能的明文为x, 他使$Pr[\mathbf{X}=x]$概率最大

* 如果我们知道了ciphertext 是y, 我们猜测最有可能的明文为x, 他使$Pr[\mathbf{X}=x\vert \mathbf{Y}=y]$概率最大. 

* 有一种特殊情况, $Pr[\mathbf{X}=x\vert\mathbf{Y}=y]=Pr[\mathbf{X}=x]$. 即使我们知道了ciphertext y, 我们依然不能得到额外的信息。这种情况就被称为 ***"Perfect secrecy"*** (Shift cipher就有perfect secrecy)

<br>

`Definition`{:.warning}

A cryptosystem has perfect secrecy if $Pr[\mathbf{X=x\vert\mathbf{Y}=y}]=Pr[\mathbf{X}=x]$ for any x, y

If $Pr[y]>0$, then this is equivalent to $Pr[\mathbf{X}=x,\mathbf{Y}=y]=Pr[\mathbf{X}=x]\cdot Pr[\mathbf{Y}=y]$

If $Pr[y]>0$ for all y, then this is equivalent to "x,y" independent.

<br>

接下来，我们会从更general地去分析perfect secrecy. 我们先做一个合理的假设$Pr[y]>0$ for any y. (如果$Pr[y_0]=0$, 就将 $y_0$ 从ciphertext space中剔除) . 同样，假设 $Pr[x]>0$ for any x. Then x, y are independent.

Recall:

$Pr[y]=\sum_{k:y=e_k(x)}Pr[k]Pr[\mathbf{X}=d_k(y)]$

$Pr[y\vert x]=\sum_{k:y=e_k(x)}Pr[k]$

因此，对于任意$y\in C$, 必须有一个key k使得$e_k(x)=y$, 所以$\vert K\vert\geq \vert C\vert$.

在任何cryptosystem中，因为从plaintext到ciphertext是单射，我们必须有$\vert  C\vert\geq\vert P\vert$.

在$\vert K\vert=\vert C\vert=\vert P\vert$到情况下，我们可以得到一些特性

<br>

`Theorem`{:.error}

假设 $(\mathscr{P}, \mathscr{C}, \mathscr{K},\mathscr{E},\mathscr{D})$ 是一个cryptosystem, $\vert \mathscr{P}\vert=\vert\mathscr{C}\vert=\vert\mathscr{K}\vert$, 对于所有$x$, y, $Pr(x)>0$, $Pr[y]>0$. 那么他有perfect secrecy当且仅当

* $Pr(k)=\frac{1}{\vert k\vert}$
* 对于任意数对$(x,y)$, 存在唯一的$k$, 使得$y=e_K(x)$

Proof:

* 先证$\Leftarrow$

$Pr[y]=\sum_{k:y=e_k(x)}Pr[k]Pr[\mathbf{X}=d_k(y)]=\frac{1}{\vert k\vert}$

$Pr[y\vert x]=\sum_{k:y=e_k(x)}Pr[k]=\frac{1}{\vert k\vert}$

$Pr[x\vert y]=\frac{Pr[x]\cdot\frac{1}{\vert k\vert}}{\frac{1}{\vert k\vert}}=Pr[x]$

有perfect secrecy

* 再证$\Rightarrow$

前面的观察中，我们得到了$\vert K\vert \geq \vert C\vert\geq\vert P\vert$. 因为我们有$\vert K\vert=\vert C\vert=\vert P\vert$, 所以我们可以得到对于任意$x\in P,y\in C$, 只有一个key k, 使得$e_k(x)=y$

记$n=\vert K\vert$, 令$P=\{x_i:1\leq i\leq n\}$ 并且固定一个ciphertext element $y\in C$. 我们可以令$k_1,k_2,\cdots k_n$ 使得$e_{k_i}(x_i)=y$

根据Bayes's theorem, 我们有

$Pr[x_i\vert y]=\frac{Pr[y\vert x_i]Pr[x_i]}{Pr[y]}=\frac{Pr[K=k_i]Pr[x_i]}{Pr[y]}$

因为perfect secrecy, 所以$Pr[x_i\vert y]=Pr[x_i]$, 推出$Pr[K=k_i]=Pr[y]$

这说明了所有key的出现概率是相同的，都等于$Pr[y]$, 因此$Pr[k]=\frac{1}{\vert K\vert}$



### One-time Pad

One well-known realization of perfect secrecy is the One-time Pad.

<br>

Let $n\geq 1$ be an integer, and take $\mathscr{P}=\mathscr{C}=\mathscr{K}=(\mathbb{Z}_2)^n$. For $K\in (\mathbb{Z}_2)^n$, define $e_K(x)$ to be the vector sum module 2 of K and x. So, if $x=(x_1,\cdots,x_n)$ and $K=(K_1,\cdots,K_n)$, then

$$e_K(x)=(x_1+K_1,\cdots,x_n+K_n)\mod 2$$

If $y=(y_1,\cdots,y_n)$, then 

$$d_K(y)=(y_1+K_1,\cdots,y_n+K_n)\mod 2$$

<br>

通常n比较大，可以是1w, 10w, ..., key的共享是困难的。



# 4. Entropy

我们将注意力集中到一种特殊的场景: 一个key只用于一次encryption. 我们现在想知道如果更多的明文被同样的key加密，在给定充足时间的情况下，有多大的可能被ciphertext-only attack攻破。研究这个问题的一个重要工具是entropy

entropy可以被认为是信息或者不确定性的数学度量，可以通过概率分布被计算出来

`definition`{:.warning}

假定$\mathbf{X}$是在有限集X上的离散型随机变量。那么$\mathbf{X}$的熵被定义为

$$H(\mathbf{X})=-\sum_{x\in X}Pr[x]log_2Pr[x]$$

Remark: if $Pr[x]=0$, then it contribute 0 to the summation

Let $f(t):=-tlog_2t,t >0$. It's a continuous function. $f(0)=\underset{t\rightarrow 0^+}{lim}f(t)=0$

<img src="../../../assets/images/image-20200414142826526.png" alt="image-20200414142826526" style="zoom:40%;" />

1. $f(t)\geq 0\;for\;0\leq t\leq 1$

2. $H(x)\leq log_2n, n=\vert x\vert$ by Jason inequality

Proof: $H(x)=\sum_{x}Pr[x]log_2(\frac{1}{Pr[x]})\leq log_2(\sum_xPr[x]\frac{1}{Pr[x]})\leq log_2n$

<br>

e.g. 

1. $X=\{1,2,\cdots,n\}$, $Pr[\mathbf{X}=i]=\frac{1}{n}$

$H(x)=-\sum_{i=1}^n\frac{1}{n}log_2(\frac{1}{n})=log_2n$

2. $X=\{1,2,\cdots,n\}$

 $$Pr[\mathbf{X}=i]=\begin{aligned}1,i=1\\0,i\not=1\end{aligned}$$

$H(x)=0$

可以看到熵为0，这是一个确定性事件

<br>

## 4.1 Huffman Encodings

Let $\mathbf{X}$ be a random variable which takes on values from a finite set $X$ and $p$ is the associated probability distribution.

An encoding of $\mathbf{X}$ is any mapping 

$$f:X\mapsto \{0,1\}^*$$

$\{0,1\}^*$表示0和1组成的有限字符串

<br>

给定一个有限字符串$x_1\cdots x_n$, 其中$x_i\in X$, 我们可以扩展$f$

$f(x_1x_2\cdots x_n)=f(x_1)\Vert\cdots\Vert f(x_n)$, $\Vert$表示连接

这样，我们可以认为$f$ 是一个映射

$$f:X^*\mapsto \{0,1\}^*$$

<br>

一个encoding被称为***prefix-free encoding***如果:

不存在两个元素$x,y\in X$, 使得$g(x)=g(y)\Vert z$, 字符串$z\in\{0,1\}^*$，

<br>

Q: 如何衡量编码的efficiency呢？

A: Use weighted average length $l(f)$

$l(f)=\sum_{x\in X}Pr[x]\vert f(x)\vert$

<br>

Problem: find an injective encoding f that minimizes $l(f)$

Solution: Huffman encoding.(prefix-free)

$H(\mathbf{X})\leq l(f)<H(\mathbf{X})+1$



# 5. Properties of Entropy

`Definition`{:.warning}

A real-valued function $f$ is a ***concave***  function(凸函数) on an interval $I$ if 

$$f(\frac{x+y}{2})\geq \frac{f(x)+f(y)}{2}$$

for all $x,y\in I$. $f$ is strictly concave function on an interval $I$ if 

$$f(\frac{x+y}{2})>\frac{f(x)+f(y)}{2}$$

for all $x,y\in I,x\not=y$

<br>

`Theorem`{:.error}

Jensen's inequality

假设$f$是区间$I$上连续，并且是严格凸函数。如果

$\sum_{i=1}^na_i=1$, $a_i>0,1\leq i\leq n$. 那么有

$$\sum_{i=1}^na_if(x_i)\leq f(\sum_{i=1}^na_ix_i)$$

其中$x_i\in I,1\leq i\leq n$. 等号在$x_1=\cdots=x_n$时取到

<br>

`Theorem`{:.error}

1. $\mathbf{X}$ 是在$S=\{x_1,\cdots,x_n\}$上的随机变量， $Pr[x_i]=p_i$, 那么$H(x)\leq log_2n$。 等号当且仅当$p_i=\frac{1}{n}$时成立
2. $H(\mathbf{X},\mathbf{Y})\leq H(\mathbf{X})+H(\mathbf{Y})$，等号当且仅当$\mathbf{X},\mathbf{Y}$独立时成立

Proof:

(1). $$\begin{aligned}H(x)&=-\sum_{i=1}^n p_ilog_2p_i\\&=\sum_{i=1}^n p_ilog_2\frac{1}{p_i}\\&\leq log_2\sum_{i=1}^n(p_i\times \frac{1}{p_i})\\&=log_2n\end{aligned}$$

