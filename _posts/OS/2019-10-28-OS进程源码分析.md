---
title: "Linux进程 源码分析"
tags: Operating-system
key: page-OSsrccode

---

<!--more-->

# 1. task_struct分析

```cpp
struct task_struct {
    //-1表示不可运行，0表示可以运行，>0表示停止
    volatile long state;
    void* stack;
    atomic_t usage;
    //进程标志，下文定义
    unsigned long flags;
    unsigned long ptrace;
    //大内核锁深度
    int lock_depth;
    
    int prio, static_prio, normal_prio;
    struct list_head run_list;
    const struct sched_class* sched_class;
    struct sched_entity se;
    
    unsigned short ioprio;
    
    unsigned long policy;
    cpumask_t cpus_allowed;
    unsigned int time_slice;
    
#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
    struct sched_info sched_info;
#endif
    
    struct list_head tasks;
    
    //ptrace_list/ptrace_children的链表时ptrace能够看到的当前进程的子进程列表
    struct list_head ptrace_children;
    
    struct list_head ptrace_list;
    
    struct mm_struct *mm, *active_mm;
    
	//进程状态
    struct linux_binfmt *binfmt;
    long exit_state;
    int exit_code, exit_signal;
    int pdeath_signal;	//再父进程终止时发送的信号
    
    unsigned int personality;
    unsigned did_exec:1;
    pid_t pid;
    pid_t tpid;
}
```

<table>
  <tr>
    <td>
     <img src="https://miaochenlu.github.io/picture/image-20191114231138100.png" alt="image-20191114231138100" style="zoom:50%;" />
    </td>
    <td>
      <img src="https://miaochenlu.github.io/picture/linux_task_struct_data.png" alt="linux_task_struct_data" style="zoom:67%;" />
    </td>
  </tr>
</table>

### i. state 进程状态

- TASK_RUNNING
- TASK_INTERRUPTIBLE
- TASK_UNINTERRUPTIBLE
- TASK_STOPPED
- TASK_TRACED
- EXIT_ZOMBIE
- EXIT_DEAD

state指定了进程的当前状态，可使用下列值（这些是预处理器常数，定义在<sched.h>中）。

- **TASK_RUNNING**意味着进程处于可运行状态。这并不意味着已经实际分配了CPU。进程可能会 一直等到调度器选中它。该状态确保进程可以立即运行，而无需等待外部事件。
- **TASK_INTERRUPTIBLE**是针对等待某事件或其他资源的睡眠进程设置的。在内核发送信号给该 进程表明事件已经发生时，进程状态变为TASK_RUNNING，它只要调度器选中该进程即可恢复 执行。
- **TASK_UNINTERRUPTIBLE**用于因内核指示而停用的睡眠进程。它们不能由外部信号唤醒，只能 由内核亲自唤醒。
- **TASK_STOPPED**表示进程特意停止运行，例如，由调试器暂停。
- **TASK_TRACED**本来不是进程状态，用于从停止的进程中，将当前被调试的那些（使用ptrace机 制）与常规的进程区分开来。 下列常量既可以用于struct task_struct的进程状态字段，也可以用于exit_state字段，后者 明确地用于退出进程。
- **EXIT_ZOMBIE**如上所述的僵尸状态。
- **EXIT_DEAD**状态则是指wait系统调用已经发出，而进程完全从系统移除之前的状态。只有多 个线程对同一个进程发出wait调用时，该状态才有意义

> 僵尸状态？
>
> 进程终止需要两个条件：
>
> - 第一，程序必须由另一个进程或一个用户杀死（通常是通过发送SIGTERM或SIGKILL 信号来完成，这等价于正常地终止进程）
> - 第二，进程的父进程在子进程终止时必须调用或已经调用wait4（读做wait for）系统调用。 这相当于向内核证实父进程已经确认子进程的终结。该系统调用使得内核可以释放为子进程保留的资源。
>
> 只有在第一个条件发生（程序终止）而第二个条件不成立的情况下（ wait4），才会出现“僵尸” 状态。在进程终止之后，其数据尚未从进程表删除之前，进程总是暂时处于“僵尸”状态。





### ii.  pid

进程和进程描述符之间有非常严格的一一对应关系。用PID来表示进程，他放在进程描述符的pid字段中。PID被顺序编号。

由于循环使用PID编号，内核通过管理pidmap-array位图来表示当前应分配的PID和空闲的PID



### iii. stack, thread_info

linux内核为每个进程提供了内核栈kernel stack

```cpp
struct task_struct {
...
   void* stack;
...
}
```

<img src="https://miaochenlu.github.io/picture/image-20191114234131486.png" alt="image-20191114234131486" style="zoom:50%;" />

Why thread_info?

> task_struct is huge. it's around 1,7KB on a 32 bit machine. on the other hand, you can easily see that thread_info is much slimmer.
>
> kernel stack is either 4 or 8KB, and either way a 1.7KB is pretty much, so storing a slimmer struct, that points to task_struct, immediately saves a lot of stack space and is a scalable solution.

```cpp
union thread_union {
  struct thread_info thread_info;
  unsigned long stack[2048];
};
```

```cpp
struct thread_info {
    unsigned long        flags;        //ow level flags
    mm_segment_t        addr_limit;    //address limit
    struct task_struct    *task;       //main task structure 
    int            preempt_count;    	 //0 => preemptable, <0 => bug
    int            cpu;        				 //cpu
};
```



### iv. list_head

```cpp
struct task_struct {
...
  struct list_head run_list;
...
};
```

```cpp
struct list_head {
  struct list_head* next, *prev;
};
```

<img src="https://miaochenlu.github.io/picture/image-20191114235421594.png" alt="image-20191114235421594" style="zoom:50%;" />



### v. 进程关系

* 如果进程A分支形成进程B，进程A称之为父进程而进程B则是子进程。

  如果进程B再次分支建立另一个进程C，进程A和进程C之间有时称之为祖孙关系。 

* 如果进程A分支若干次形成几个子进程B1，B2，...，Bn，各个Bi进程之间的关系称之为兄弟关系 

<img src="https://miaochenlu.github.io/picture/image-20191103183858458.png" alt="image-20191103183858458" style="zoom:50%;" />

task_struct数据结构提供了两个链表表头，用于实现这些关系

```cpp
struct task_struct {
  ....
  struct list_head children;	//子进程列表
  struct list_head silbing;		//连接到父进程的子进程链表
}
```

* children是链表表头，该链表中保存有进程的所有子进程
* sibling用于将兄弟进程彼此连接起来

新的子进程置于sibling链表的起始位置，这意味着可以重建进程分支的时间顺序





# 2. 创建进程

* fork

  建立父进程的一个完整副本，然后作为子进程执行。为了减少与该调用相关的工作量，Linux使用了写时复制技术

* vfork

  类似于fork，但是并不创建父进程数据的副本，父子进程之间共享数据，可以节省大量CPU时间

* clone

  产生线程，可以对父子进程之间的共享，复制进行精确控制

clone的标志[用来指定控制复制过程中的一些属性]

| -                    | -                                                            |
| -------------------- | ------------------------------------------------------------ |
| CLONE_VM             | 共享内存描述符和所有的页表                                   |
| CLONE_FS             | 共享根目录和当前                                             |
| CLONE_FILES          | 共享打开文件表                                               |
| CLONE_SIGHAND        | 共享信号处理程序的表，阻塞信号表和挂起信号表                 |
| CLONE_PTRACE         | 如果父进程被跟踪，子进程则也被跟踪                           |
| CLONE_VFORK          | 在发出vfork()系统调用时设置                                  |
| CLONE_PARENT         | 设置子进程的父进程为调用进程的父进程                         |
| CLONE_THREAD         | 把子进程插入到父进程的同一线程组中，并迫使子进程共享父进程的信号描述符，因此也设置子进程的tgid字段和group_leader |
| CLONE_NEWNS          | 当clone需要自己的命名空间时，设置这个标志                    |
| CLONE_SYSVSEM        | 共享system V IPC取消信号量的操作                             |
| CLONE_SETTLS         | 为轻量级进程创建新的线程局部存储段(TLS)                      |
| CLONE_PARENT_SETTID  | 把子进程的PID写入由pid参数所指向的父进程的用户态变量         |
| CLONE_CHILD_CLEARTID | 如果该标志被设置，则内核建立起一种触发机制，用在子进程将要退出或要开始执行新程序时 |
| CLONE_DETRACHED      | 遗留标志，忽略                                               |
| CLONE_UNTRACED       | 使得CLONE_PTRACE失去作用                                     |
| CLONE_CHILD_SETTID   | 把子进程的PID写入由ctid参数所指向的子进程的用户态变量中      |
| CLONE_STOPPED        | 强迫子进程开始于TASK_STOPPED状态                             |



fork, vfork和clone的系统调用的入口地址分别是sys_fork, sys_vfork和sys_clone

```cpp
asmlinkage int sys_fork(struct pt_regs regs) {
  return do_fork(SIGCHILD, regs.esp, &regs, 0, NULL, NULL);
}
//子进程终止后发送SIGCHLD信号通知父进程
```

```cpp
asmlinkage int sys_clone(struct pt_regs regs) {
  unsigned long clone_flags;
  unsigned long newsp;
  int __user* parent_tidptr, *child_tidptr;
  
  clone_flags = regs.ebx;
  newsp = regs.ecx;
  parent_tidptr = (int __user*)regs.edx;
  child_tidptr = (int __user*)regs.edi;
  if(!newsp)
    newsp = regs.esp;
  return do_fork(clone_flags, newsp, &regs, 0, parent_tidptr, child_tidptr);
}
```



do_fork函数处理clone(), fork(), vfork()系统调用

<img src="https://miaochenlu.github.io/picture/image-20191114224108043.png" alt="image-20191114224108043" style="zoom:50%;" />

do_fork()函数的参数

```cpp
long do_fork(unsigned long clone_flags,	//标志集合，用来指定控制复制过程中的一些属性
             unsigned long stack_start,	//用户状态下栈的起始地址
             struct pt_regs* regs,			//指向寄存器集合的指针
             unsigned long stack_size,	//用户状态下栈的大小
             int __user* parent_tidptr,	//指向父进程pid
             int __user* child_tidptr)	//指向子进程pid
{
  return _do_fork(clone_flags, stack_start, stack_size, parent_tidptr, child_tidptr, 0);
}
```

do_fork()函数利用辅助的copy_process来创建进程描述符以及子进程需要的其他内核数据结构

* 通过查找`pidmap_array`位图，为子进程分配新的PID

* 检查父进程的`ptrace`字段，如果不为0， 说明另外有一个进程正在跟踪父进程。因此，do_fork检查debugger是否自己想跟踪子进程。在这种情况下，如果子进程不是内核线程，那么`do_fork()`函数设置`CLONE_PTRACE`标志

* 调用`copy_process()`复制进程描述符，如果所有必须的资源都是可用的，该函数返回刚创建的task_struct描述符的地址

* 如果设置了`CLONE_STOPPED`标志，或者必须跟踪子进程，即在`p->ptrace`中设置了`PT_PTRACED`标志，那么子进程的状态被设置为`TASK_STOPPED`, 并为子进程增加挂起的SIGSTOP信号，在另外一个进程把子进程的状态恢复为`TASK_RUNNING`之前，子进程将一直保持`TASK_STOPPED`状态
* 如果没有设置`CLONE_STOPPED`标志，则调用`wake_up_new_task()`函数以执行
  * 调整父进程和子进程的调度参数
  * 如果子进程和父进程运行在一个CPU上，而且父进程和子进程不能共享同一组页表(`CLONE_VM`被清零)，那么，就把子进程插入父进程运行队列，且子进程在父进程之前
  * 如果子进程和父进程运行在不同的CPU上，或者父进程和子进程共享同一组页表(`CLONE_VM`被置位)，就把子进程插入父进程运行队列的队尾
* 如果`CLONE_STOPPED`标志被设置，则把子进程置位`TASK_STOPPED`状态
* 如果父进程被跟踪，则把子进程的`PID`存入current的`ptrace_message`字段并调用`ptrace_notify()`。这使当前进程停止运行，并向当前进程的父进程发送SIGCHLD信号
* 如果设置了`CLONE_VFORK`, 则把父进程插入等待队列，并挂起父进程直到子进程释放自己的内存地址空间
* 结束并返回子进程的PID

```cpp
long _do_fork(unsigned long clone_flags,
      unsigned long stack_start,
      unsigned long stack_size,
      int __user *parent_tidptr,
      int __user *child_tidptr,
      unsigned long tls) {
  //创建新的task_struct
  struct task_struct* p;
  int trace = 0;
  long nr;
  
  if(!(clone_flags & CLONE_UNTRACED)) {
    
    if(clone_flags & CLONE_VFORK)
      trace = PTRACE_EVENT_VFORK;
    else if((clone_flags & CSIGNAL) != SIGCHLD)
      trace = PTRACE_EVENT_CLONE;
    else 
      trace = PTRACE_EVENT_FORK;
  }
  if(likely(!ptrace_event_enabled(current, trace)));
  
  //  复制进程描述符
  p = copy_process(clone_flags, stack_start, stack_size, child_tidptr, NULL, trace, tls);
  
  if(!IS_ERR(p)) {
    struct completion vfork;
    struct pid* pid;
    
    trace_sched_process_fork(current, p);
    //获取新进程的pid信息
    pid = get_task_pid(p, PIDTYPE_PID);
    nr = pid_vnr(pid);
    
    if(clone_flags & CLONE_PARENT_SETTID)
      put_user(nr, parent_tidptr);
    //如果调用vfork()
    if(clone_flags & CLONE_VFORK) {
      p->vfork_done = &vfork;
      init_completion(&vfork);
      get_task_struct(p);
    }
    //将子进程加入调度器
    wake_up_new_task(p);
    
    if(unlikely(trace))
      ptrace_event_pid(trace, pid);
    if(clone_flags & CLONE_VFORK) {
      if(!wait_for_vfork_done(p, &vfork))
        ptrace_event_pid(PTRACE_EVENT_VFORK_DONE, pid);
    }
    put_pid(pid);
  } else {
    nr = PTR_ERR(p);
  }
  return nr;
}
```



# 3. 进程调度

## 3.1 overview

<img src="https://miaochenlu.github.io/picture/process_schedule.png" alt="process_schedule" style="zoom: 67%;" />

<img src="https://miaochenlu.github.io/picture/process_schedule_impl.jpg" alt="process_schedule_impl" style="zoom: 20%;" />

进程调度的任务

* 调度策略
* 上下文切换



task_struct中与调度有关的成员

```cpp
struct task_struct {
...
  int prio, static_prio, normal_prio;
  //rt_priority表示实时进程的优先级。最低为0，最高为99.越大优先级越高
  unsigned int rt_priority;
  //表头，用于维护包含各进程的一个运行表
  struct list_head run_list;
  //表示进程所属调度器类
  const struct sched_class *sched_class;
  //表示调度策略
  unsigned int policy;
  //位域 用来限制在那些CPU上可以运行
  cpumask_t cpus_allowed;
  //可使用CPU的剩余 时间段
  unsigned int time_slice;
...
}
```

<img src="https://miaochenlu.github.io/picture/image-20191103192022581.png" alt="image-20191103192022581" style="zoom:50%;" />

#### A. Linux实现两个调度器

- 一种是直接的, 比如进程打算睡眠或出于其他原因放弃CPU
- 另一种是通过周期性的机制, 以固定的频率运行, 不时的检测是否有必要



#### B. linux 调度的一些policy

| **符号常量**     | **意义**                 |
| ---------------- | ------------------------ |
| **SCHED_NORMAL** | 普通进程的时间片轮转算法 |
| **SCHED_FIFO**   | 实时进程的先进先出算法   |
| **SCHED_RR**     | 实时进程的时间片轮转算法 |
| **SCHED_BATCH**  | 后台处理进程             |

#### C. Linux的调度器类

* fair_sched_class，现在较高版本的Linux上也就是CFS(Completely Fair Scheduler)，Linux上面主要的调度方式，由CONFIG_FAIR_GROUP_SCHED宏控制
* rt_sched_class，由CONFIG_RT_GROUP_SCHED宏控制，实时调度类型
* dl_sched_class，deadline调度类，实时调度中较高级别的调度类型，一般之后在系统紧急情况下会调用；
* stop_sched_class，最高优先级的调度类型，属于实时调度类型的一种，在系统终止时会在其上创建进程进入调度。
* idle_sched_class，优先级最低，在系统空闲时才会进入该调度类型调度，一般系统中只有一个idle，那就是初始化进程init_task，在初始化完成后它将自己设置为idle进程，并不做更多工作

调度顺序为

stop_sched_class --> dl_sched_class --> rt_sched_class --> fair_sched_class --> idle_sched_class



#### D. Linux的调度实体

| 调度实体        | 名称             | 描述                                           | 对应调度器类     |
| --------------- | ---------------- | ---------------------------------------------- | ---------------- |
| sched_dl_entity | DEADLINE调度实体 | 采用EDF算法调度的实时调度实体                  | dl_sched_class   |
| sched_rt_entity | RT调度实体       | 采用Roound-Robin或者FIFO算法调度的实时调度实体 | rt_sched_class   |
| sched_entity    | CFS调度实体      | 采用CFS算法调度的普通非实时进程的调度实体      | fair_sched_class |



## 3.2 进程选择与运行时间

<img src="https://miaochenlu.github.io/picture/image-20191103185651055.png" alt="image-20191103185651055" style="zoom:50%;" />

所有可运行进程都按照等待时间在**<u>红黑树</u>**中排序。等待CPU时间最长的进程是最左侧的项，调度器下一次会考虑该进程。等待时间稍短的进程在该树上从左至右进行排序。

除了红黑树，就绪队列还装备了**<u>虚拟时钟</u>**。

虚拟时钟的时间：如果队列上有4个进程，那么虚拟时钟以实际时钟的1/4的速度运行。

假定就绪队列的虚拟时间由`fair_clock`给出，而进程的等待时间保存在`wait_runtime`中。为了排序红黑树上的进程，内核使用差值

`fair_clock-wait_runtime`排序

不是所有进程都是同样重要的。为了确定特定进程的重要性，linux给进程增加了相对优先级属性。

task_struct采用了3个成员变量来表示进程的优先级

* prio	动态优先级
* normal_prio 动态优先级
* static_prio 静态优先级

1. **<u>static_prio</u>**是进程启动时分配的优先级，可以用nice和sched_setscheduler系统调用修改。否则在进程运行期间会一直保持恒定。
   * static_prio的值越小，优先级越高
   * 0-99用于real-time processes[无实际意义]，100-139用于普通进程
2. **<u>normal_protity</u>**表示基于进程的static_prio和调度策略计算出的优先级。因此，即使普通进程和实时进程具有相同的static_prio，其normal_prio也是不同的。进程分支时，子进程会继承normal_prio
3. **<u>prio</u>** 调度器考虑的优先级保存在prio中。
4. **<u>rt_priority</u>** 表示实时优先级

由于某些情况下内核需要暂时提高进程的优先级。因此需要3个成员来表示



<img src="https://miaochenlu.github.io/picture/image-20191109154038203.png" alt="image-20191109154038203" style="zoom: 80%;" />

<img src="https://miaochenlu.github.io/picture/771adb345f01f5f2f7f816f57fae9e1e20170314104605.png" alt="771adb345f01f5f2f7f816f57fae9e1e20170314104605" style="zoom:80%;" />

```cpp
#define MAX_USER_RT_PRIO		100
#define MAX_RT_PRIO					MAX_USER_RT_PRIO		//实时进程最大值
#define MAX_PRIO						(MAX_RT_PRIO + 40)	
#define DEFAULT_PRIO				(MAX_RT_PRIO + 20)	//默认nice值为0

#define NICE_TO_PRIO(nice) 	(MAX_RT_PRIO + (nice) + 20)
#define PRIO_TO_NICE(prio)	((prio) - MAX_RT_PRIO - 20)
#define TASK_NICE(p)				PRIO_TO_NICE((p)->static_prio)
```



#### 计算优先级

static_prio时预先设置好的，还需要计算动态优先级(`task_struct->prio`)和普通优先级(`task_struct->normal_prio`)

优先级由`p->prio = effective_prio(p)`得出

```cpp
static int effective_prio(struct task_struct* p) {
  //计算normal_prio
  p->normal_prio = normal_prio(p);
  //如果不是实时进程，则返回普通优先级
  if(!rt_prio(p->prio))
    return p->normal_prio;
  //如果已经提高到实时进程，则保持优先级不变
  return p->prio;
}
```



```cpp
static inline int normal_prio(struct task_struct* p) {
  int prio;
  if(task_has_rt_policy(p))//实时进程normal_prio的计算
    prio = MAX_RT_PRIO - 1 - p->rt_priority;
  else	//非实时进程normal_prio的计算
    prio = __normal_prio(p);//返回的是static_prio
  return prio;
}
```

```cpp
static inline int __normal_prio(struct task_struct* p) {
  return p->static_prio;
}
```

<img src="https://miaochenlu.github.io/picture/image-20191109155947333.png" alt="image-20191109155947333" style="zoom:50%;" />



#### 计算负荷权重

```cpp
struct load_weight {
  unsigned long weight, inv_weight;
};
```



进程每降低一个nice值，就会相对其他多获得10%CPU时间。下面将nice值转换成权重值

如果两个进程A和B，nice级别都为0，那么每个进程分到$\frac{1024}{1024+1024}=50\%$

如果进程B的nice级别变成1，那么B进程分到$\frac{820}{1024+820}=45\%$

```cpp
static const int prio_to_weight[40] = {
  /*-20*/	 	88761, 71755, 56483, 46273, 36291,
  /*-15*/	  29145, 23254, 18705, 14949, 11916,
  /*-10*/		 9548,  7620,  6100,  4904,  3906,
  /* -5*/		 3121,  2501,  1991,  1586,  1277,
  /*	0*/		 1024,   820,   655,   526,   423,
  /*	5*/ 	  335,   272,   215,   172,   137,
  /* 10*/			110,	  87, 	 70,	  56, 	 45,
  /* 15*/			 36, 		29,		 23, 		18, 	 15,
};
```



```cpp
#define WEIGHT_IDLEPRIO 	2
#define WMULT_IDLEPRIO		(1 << 31)
static void set_load_weight(struct task_struct* p) {
  if(task_has_rt_policy(p)) {	//实时进程
    p->se.load.weight = prio_to_weight[0] * 2;
    p->se.load.inv_weight = prio_to_wmult[0] >> 1;
    return;
  }
  
  if(p->policy == SCHED_IDLE) {
    p->se.load.weight = WEIGHT_IDLEPRIO;
    p->se.load.inv_weight = WMULT_IDLEPRIO;
    return;
  }
  p->se.load.weight = prio_to_weight[p->static_prio - MAX_RT_PRIO];
  p->se.load.inv_weight = prio_to_wmult[p->static_prio - MAX_RT_PRIO];
}
```



```cpp
static inline void update_load_add(struct load_weight* lw, unsigned long inc) {
  lw->weight += inc;
}

static inine void inc_load(struct rq* rq, const struct task_struct* p) {
  update_load_add(&rq->load, p->se.load.weight);
}

static void inc_nr_running(struct task_struct* p, struct rq* rq) {
  rq->nr_running++;	//进程数量+1
  inc_load(rq, p);	//负荷增加
}

```



### 分配进程运行时间的计算

```cpp
static u64 sched_slice(struct cfs_rq* cfs_rq, struct sched_entity* se) {
  u64 slice = __sched_period(cfs_rq->nr_running);
  
  slice *= se->load.weight;
  do_div(slice, cfs_rq->load.weight);
  return slice;
}
```

虚拟时钟的时间片

```cpp
static u64 __sched_vslice(unsigned long rq_weight, unsigned long nr_running) {
  u64 vslice = __sched_period(nr_running);
  vslice *= NICE_0_LOAD;
  do_div(vslice, rq_weight);
  return vslice;
}
```

```cpp
static u64 sched_vslice(struct cfs_rq* cfs_rq) {
  return __sched_vslice(cfs_rq->load.weight, cfs_rq->nr_running);
}
```



## 3.3 调度器

linux实现了两个调度器

- 一种是直接的, 比如进程打算睡眠或出于其他原因放弃CPU
- 另一种是周期性的, 以固定的频率运行, 不时的检测是否需要调度

#### A. 周期性调度器

周期性调度器的任务是

* 更新相关统计量
* 激活负责当前进程调度类的周期性调度方法

```cpp
void scheduler_tick(void) {
  int cpu = smp_processor_id();
  struct rq* rq = cpu_rq(cpu);
  struct task_struct* curr = rq->curr;
...
  __update_rq_clock(rq);
  update_cpu_load(rq);
  
  if(curr != rq->idle)
    curr->sched_class->task_tick(rq, curr);
}
```





#### B. 主调度器

```cpp
asmlinkage void __sched schedule(void) {
  struct task_struct* prev, *next;
  struct rq* rq;
  int cpu;
  
need_resched:
  cpu = smp_processor_id();
  rq = cpu_rq(cpu);		//获取当前cpu的就绪队列
  prev = rq->curr;		//在prev中保存仍然指向活动进程task_struct的指针
...
  __update_rq_clock(rq);				//更新就绪队列的时钟
  clear_tsk_need_resched(prev);	//清楚当前运行进程task_struct中的重调度标志TIF_NEED_RESCHED
...
  if(unlikely(prev->state & TASK_INTERRUPTIBLE) && unlikely(signal_pending(prev))) {
    //如果当前进程原来处于可中断睡眠状态而且现在接收到信号，那么他必须再次提升为运行进程
    prev->state = TASK_RUNNING;
  } else {
    //否则，相应调度器类的方法使进程停止活动
    deactivate_task(rq, prev, 1);	//sched_class->dequeue_task
  }
...
  //put_prev_task首先通知调度器类当前运行的进程要被另一个进程代替，这提供一个时机，供执行一些簿记工作并更新统计量
  prev->sched_class->put_prev_task(rq, prev);
  next = pick_next_task(rq, prev);
...
  if(likely(prev != next)) {	//如果选择了新进程，上下文切换
    rq->curr = next;
    context_switch(rq, prev, next);
  }
...
  if(unlikely(test_thread_flag(TIF_NEED_RESCHED)))
    go need_resched;
}
```



与fork的交互

```cpp
void sched_fork(struct task_struct* p, int clone_flags) {
  p->prio = current->normal_prio;//继承normal_prio
  if(!rt_prio(p->prio))
    p->sched_class = &fair_sched_class;
...
}
```



## 3.4调度器类

```cpp
struct sched_class {
    const struct sched_class* next;
    void (*enqueue_task) (struct rq* rq, struct task_struct* p, int wakeup);
    void (*dequeue_task) (struct rq* rq, struct task_struct* p, int sleep);
    //进程主动放弃cpu控制权
    void (*yield_task) (struct rq* rq);
    //用一个新唤醒的进程来抢占当前进程
    void (*chech_preempt_curr) (struct rq* rq, struct task_struct* p);
    //选择下一个将要运行的进程
    struct task_struct* (*pick_next_task)(struct rq* rq);
    //用另一个进程代替当前运行的进程之前调用
    void (*put_prev_task) (struct rq* rq, struct task_struct* p);
    void (*set_curr_task) (struct rq* rq);
    //周期性调度器调用
    void (*task_tick) (struct rq* rq, struct task_struct* p);
    void (*task_new) (struct rq* rq, struct task_struct* p);
};
```

### 完全公平调度类

```cpp
static const struct sched_class fair_sched_class = {
  .next = &idle_sched_class,
  .enqueue_task = enqueue_task_fair,
  .dequeue_task = dequeue_task_fair,
  .yield_task = yield_task_fair,
  .check_preempt_curr = check_preempt_wakeup,
  .pick_next_task = pick_next_task_fair,
  .put_prev_task = put_prev_task_fair,
...
  .set_curr_task = set_curr_task_fair,
  .task_tick = task_tick_fair,
  .task_new = task_new_fair,
};
```

如何选择下一个task

```cpp
static inline struct task_struct* pick_next_task(struct rq* rq) {
    const struct sched_class* class;
    struct task_struct* p;

    //如果所有进程都是普通进程，则用CFS调度
    if(likely(rq->nr_running == rq->cfs.nr_running)) {
        p = fair_sched_class.pick_next_task(rq);
        if(likely(p))
            return p;
    } 
    class = sched_class_highest;//优先级最高的调度类
    for(;;) {
        p = class->pick_next_task(rq);
        if(p)
            return p;
        class = class->next;
    }
}
```



### 实时调度类

两种实时类

* SCHED_RR 

  有时间片，值在进程运行时会减少

* SCHED_FIFO

  没有时间片，可以运行任意长时间

实时进程的调度类定义如下

```cpp
const struct sched_class rt_sched_class = {
  .next = &fair_sched_class,
  .enqueue_task = enqueue_task_rt,
  .dequeue_task = dequeue_task_rt,
  .yield_task 	= yield_task_rt,
  
  .check_preempt_curr = check_preempt_curr_rt,
  .pick_next_task = pick_next_task_rt,
  .put_prev_task = put_prev_task_rt,
  .set_curr_task = set_curr_task_rt,
  .task_tick = task_tick_rt,
};
```



## 3.5 调度实体

`sched_entity`结构体

```cpp
struct sched_entity {
  //权重，决定各个实体占队列总负荷的比例
    struct load_weight  load;
  //红黑树节点，使得实体可以在红黑树上排序
    struct rb_node      run_node;
    struct list_head    group_node;
  //是否在就绪队列上接收调度
    unsigned int        on_rq;
    u64                 exec_start;
  //进程消耗的cpu时间
    u64                 sum_exec_runtime;
    u64                 vruntime;
    u64                 prev_sum_exec_runtime;
    u64                 last_wakeup;
    u64                 avg_overlap;
    u64                 nr_migrations;
    u64                 start_runtime;
    u64                 avg_wakeup;
};
```

## 3.5 就绪队列

### `rq`

```cpp
struct rq {
  //所有队列上等待运行进程的数目
  unsigned long nr_running;
  #define CPU_LOAD_IDX_MAX 5
  unsigned long cpu_load[CPU_LOAD_IDX_MAX];
...
  struct load_weight load;
  //完全公平调度的就绪队列
  struct cfs_rq cfs;
  //实时调度的就绪队列
  struct rt_rq rt;
  struct task_struct* curr, *idle;
  u64 clock;
...
}
```

系统所有的就绪队列都在runqueues数组中，这个数组的每一个元素对应于系统中的一个CPU。

在单处理系统中，由于只需要一个就绪队列，数组只有一个元素

```cpp
#define cpu_rq(cpu)		(&per_cpu(runqueues, (cpu)))
#define this_rq()			(&__get_cpu_var(runqueues))
#define task_rq(p)		cpu_rq(task_cpu(p))
#define cpu_curr(cpu)	(cpu_rq(cpu)->curr)
```



### `cfs_rq`

```cpp
struct cfs_rq {
    struct load_weight load;
    unsigned long nr_running;
    u64 min_vruntime;
  //红黑树根节点
    struct rb_root tasks_timeline;
  //红黑树最左节点
    struct rb_node* rb_leftmost;
    struct sched_entity* curr;
};
```

`vruntime`变量存放进程虚拟运行时间

```cpp
/**
 * 计算当前进程的执行时间
 * 放在变量delta_exec中
 * 讲delta_exec传递给__update_curr()
 * 后者根据当前可运行进程总数对运行时间进行加权计算
 */
static void update_curr(struct cfs_rq* cfs_rq) {
    struct sched_entity* curr = cfs_rq->curr;
    u64 now = rq_of(cfs_rq)->clock;
    unsigned long delta_exec;

    if(unlikely(!curr))
        return;
    
    //获得从最后一次修改负载后当前任务所占用的运行总时间
    delta_exec = (unsigned long)(now - curr->exec_start);
    if(!delta_exec)
        return;
    __update_curr(cfs_rq, curr, delta_exec);

    if(entity_is_task(curr)) {
        struct task_struct* curtask = task_of(curr);
        trace_sched_stat_runtime(curtask, delta_exec, curr->vruntime);
        cpuacct_charge(curtask, delta_exec);
        account_group_exec_runtime(curtask, delta_exec);
    }
}
```



```cpp
static inline void 
_update_curr(struct cfs_rq* cfs_rq, struct sched_entity* curr, unsigned long delta_exec) {
    unsigned long delta_exec_weighted;
    schedstat_set(curr->exec_max, max((u64)delta_exec, curr->exec_max));
  //更新物理运行时间
    curr->sum_exec_runtime += delta_exec;
    schedstat_add(cfs_rq, exec_clock, delta_exec);
  //更新虚拟运行时间，受优先级影响
    delta_exec_weighted = calc_delta_fair(delta_exec, curr);
    curr->vruntime += delta_exec_weighted;
    update_min_vruntime(cfs_rq);
}
```



### `rt_rq`

```cpp
struct rt_rq {
  struct rt_prio_array active;
};
```

实时调度器的就绪队列是一个链表数组，优先级决定了在数组中的位置

具有相同优先级的实施进程保存在一个链表中，表头为`active.queue[prio]`

```cpp
struct rt_prio_array {
  DECLARE_BITMAP(bitmap, MAX_RT_PRIO + 1);
  struct list_head queue[MAX_RT_PRIO];
};
```

<img src="https://miaochenlu.github.io/picture/image-20191113110508097.png" alt="image-20191113110508097" style="zoom:50%;" />



## 3.6 上下文切换

```cpp
static inline void 
context_switch(struct rq* rq, struct task_struct* prev, struct task_struct* next) {
  struct mm_struct* mm, *oldmm;
  prepare_task_switch(rq, prev, next);
  mm = next->mm;
  oldmm = prev->active_mm;
  ...
  if(unlikely(!mm)) {
    next->active_mm = oldmm;
    atomic_inc(&oldmm->mm_count);
    enter_lazy_tlb(oldmm, next);
  } else {
    //向MMU提供新的信息,把虚拟内存从一个进程映射到新进程中
    switch_mm(oldmm, mm, next);
  }
  ...
  if(unlikely(!prev->mm)) {
    prev->active_mm = NULL;
    rq->prev_mm = oldmm;
  }
  ...
  //switch_to切换处理器寄存器内容和内核栈
  switch_to(prev, next, prev);
  barrier();
  //完成清理工作
  finish_task_switch(this_rq(), prev);
}
```





## 3.6 处理周期性调度器

一下`check_preempt_tick`函数用于确保没有进程能够比延迟周期中确定的份额运行得更长

```cpp
static void
check_preempt_tick(struct cfs_rq* cfs_rq, struct sched_entity* curr) {
  unsigned long ideal_runtime, delta_exec;
  ideal_runtime = sched_slice(cfs_rq, curr);//计算分配的份额
  //计算时机运行时间
  delta_exec = curr->sum_exec_runtime - curr->prev_sum_exec_runtime;
  if(delta_exec > ideal_runtime)//如果运行时间>期望时间
    	//发起重新调度请求
    	resched_task(rq_of(cfs_rq)->curr);
}
```



## 3.7 唤醒抢占

当在`try_to_wake_up`和`wake_up_new_task`中唤醒进程时，内核使用`check_preempt_curr`看是否新进程可以抢占当前运行的进程

```cpp
static void check_preempt_wakeup(struct rq* rq, struct task_struct* p) {
  struct task_struct* curr = rq->curr;
  struct cfs_rq* cfs_rq = task_cfs_rq(curr);
  struct sched_entity* se = &curr->se, *pse = &p->se;
  unsigned long gran;
  /*
  如果新进程是一个实时进程，则会立即请求重新调度，
  因为实时进程总是会抢占CFS进程
  */
  if(unlikely(rt_prio(p->prio))) {
    update_rq_clock(rq);
    update_curr(cfs_rq);
    resched_task(curr);
    return
  }
...
  //SCHED_BATCH进程不会抢占其他进程
  if(unlikely(p->policy == SCHED_BATCH))
    return;
  /*
  当运行进程被新进程抢占时，内核确保被抢占者至少已经运行了某一最小时间限额。
  这个最小值保存在sysctl_sched_wakeup_granularity
  并且要在必要的情况下转换成虚拟时间
  */
  gran = sysctl_sched_wakeup_granularity;
  if(unlikely(se->load.weight != NICE_0_LOAD))
    gran = calc_delta_fair(gran, &se->load);
...
  /*
  如果新进程的虚拟运行时间，加上最小时间限额，仍然小于当前执行进程的虚拟运行时间
  则请求重调度
  */
  if(pse->vruntime + gran < se->vruntime)
    resched_task(curr);
}
```



## 3.8 处理新进程

```cpp
static void task_new_fair(struct rq* rq, struct task_struct* p) {
  struct cfs_rq* cfs_rq = task_cfs_rq(p);
  struct sched_entity* se = &p->se, *curr = cfs_rq->curr;
  int this_cpu = smp_processor_id();
  update_curr(cfs_rq);
  place_entity(cfs_rq, se, 1);
...
  if(sysctl_sched_child_runs_first && curr->vruntime < se->vruntime) {
    swap(curr->vruntime, se->vruntime);
  }
  enqueue_task_fair(rq, p, 0);
  resched_task(rq->curr);
}
```



## 3.9 调度器增强

### SMP调度

多处理器系统相比单处理器系统需要多考虑一些问题

* CPU负荷必须尽可能公平地在所有处理器上共享
* 进程与系统中某些处理器的亲和性必须时可设置的
* 内核必须能够将进程从一个CPU迁移到另一个

在SMP系统上，每个调度器类的调度方法必须增加两个额外的函数

```cpp
struct sched_class {
...
#ifdef CONFIG_SMP
  unsigned long (*load_balance)(struct rq* this_rq, int this_cpu, 
                               struct rq* busiest, unsigned long max_load_move,
                               struct sched_domain* sd, enum cpu_idle_type idle,
                               int *all_pinned, int *this_best_prio);
  int (*move_one_task) (struct rq* this_rq, int this_cpu,
                       struct rq* busiest, struct sched_domain* sd,
                       enum cpu_idle_type idle);
#endif
...
}
```

### load_balance

```cpp
/*
 * Check this_cpu to ensure it is balanced within domain. Attempt to move
 * tasks if there is an imbalance.
 */
static int load_balance(int this_cpu, struct rq *this_rq,
                        struct sched_domain *sd, enum cpu_idle_type idle,
                        int *balance)
{
    int ld_moved, all_pinned = 0, active_balance = 0;
    struct sched_group *group;
    unsigned long imbalance;
    struct rq *busiest;
    unsigned long flags;
    struct cpumask *cpus = __get_cpu_var(load_balance_tmpmask);
    cpumask_copy(cpus, cpu_active_mask);
    schedstat_inc(sd, lb_count[idle]);
redo:
    group = find_busiest_group(sd, this_cpu, &imbalance, idle,
                               cpus, balance);
    if (*balance == 0)
        goto out_balanced;
    if (!group) {
        schedstat_inc(sd, lb_nobusyg[idle]);
        goto out_balanced;
    }
    busiest = find_busiest_queue(sd, group, idle, imbalance, cpus);
    if (!busiest) {
        schedstat_inc(sd, lb_nobusyq[idle]);
        goto out_balanced;
    }
    BUG_ON(busiest == this_rq);
    schedstat_add(sd, lb_imbalance[idle], imbalance);
    ld_moved = 0;
    if (busiest->nr_running > 1) {
        /*
         * Attempt to move tasks. If find_busiest_group has found
         * an imbalance but busiest->nr_running <= 1, the group is
         * still unbalanced. ld_moved simply stays zero, so it is
         * correctly treated as an imbalance.
         */
        all_pinned = 1;
        local_irq_save(flags);
        double_rq_lock(this_rq, busiest);
        ld_moved = move_tasks(this_rq, this_cpu, busiest,
                              imbalance, sd, idle, &all_pinned);
        double_rq_unlock(this_rq, busiest);
        local_irq_restore(flags);
        /*
         * some other cpu did the load balance for us.
         */
        if (ld_moved && this_cpu != smp_processor_id())
            resched_cpu(this_cpu);
        /* All tasks on this runqueue were pinned by CPU affinity */
        if (unlikely(all_pinned)) {
            cpumask_clear_cpu(cpu_of(busiest), cpus);
            if (!cpumask_empty(cpus))
                goto redo;
            goto out_balanced;
        }
    }
    ...
    goto out;
out_balanced:
    schedstat_inc(sd, lb_balanced[idle]);
    sd->nr_balance_failed = 0;
out_one_pinned:
    /* tune up the balancing interval */
    if ((all_pinned && sd->balance_interval < MAX_PINNED_INTERVAL) ||
        (sd->balance_interval < sd->max_interval))
        sd->balance_interval *= 2;
    ld_moved = 0;
out:
    return ld_moved;
}
```





references:  

[1]https://blog.csdn.net/gatieme/article/details/51702662

[2]https://blog.csdn.net/gatieme/article/details/51872659

[2]深入linux内核架构

[3]linux内核设计与实现

