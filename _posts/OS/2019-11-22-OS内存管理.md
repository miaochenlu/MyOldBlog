---
title: "OS虚拟内存"
tags: Operating-system
key: page-memorymanagement
---

# 1. 虚拟内存

## 1.1 物理和虚拟寻址

主存[main memory]是一个由M个连续的byte组成的数组。***每个byte都有一个物理地址与他对应***。比如第1个byte对应0的物理地址，第二个byte对应1的物理地址。

可以使用物理地址访问内存。如图，CPU向主存请求物理地址4为起点的4个bytes。

CPU执行这条加载指令时

* 会生成一个有效物理地址，通过内存总线，传递给主存
* 主存取出数据返回给CPU
* CPU将数据放在一个寄存器里。

<center><img src="https://miaochenlu.github.io/picture/image-20191122221045486.png" alt="image-20191122221045486" style="zoom: 67%;" /></center>



现在计算机都会使用虚拟寻址

CPU生成一个虚拟地址来访问主存

这个虚拟地址在被送到内存之前先转换成适当的物理地址，这个过程叫做地址翻译。需要CPU芯片上的MMU于OS合作

<center><img src="https://miaochenlu.github.io/picture/image-20191122222054227.png" alt="image-20191122222054227" style="zoom:50%;" /></center>

<br/>

## 1.2 地址空间

地址空间是以一个非负整数地址的有序集合：$\{0,1,2,\cdots\}$，

如果地址空间中的整数是连续的，那么我们说它是一个线性地址空间。

<br/>

在一个带虚拟内存的系统中，CPU从一个有$N=2^n$个地址的地址空间中生成虚拟地址，虚拟地址空间的集合为$\{0,1,2,\cdots,N-1\}$，这个虚拟地址空间就叫做一个n位地址空间，现代系统通常支持32位或者64位虚拟地址空间

物理地址空间对应于物理内存的M个字节$\{0,1,2,\cdots,M-1\}$, M并不要求是2的幂，为了简化问题，我们假设$M=2^m$

<center><img src="https://miaochenlu.github.io/picture/image-20191123110239273.png" alt="image-20191123110239273" style="zoom:50%;" /></center>

<br/>

## 1.3 虚拟内存作为缓存的工具

磁盘上的数据被分割成块，块是磁盘是主存之间的传输单元。

VM将虚拟内存分割成虚拟页[Virtual Page, VP]，每一个page是磁盘中一个块的大小，虚拟页的大小为$P=2^p$。同样物理内存也被分割为物理页[Physical Page, PP 也被称为页帧page frame]，大小也为P bytes



任意时刻，虚拟页中的页都属于以下三种状态中的一种

* 未分配的：没有磁盘数据与其对应
* 缓存的：对应磁盘中的一个块，并且缓存进了物理内存
* 未缓存的：对应磁盘中的一个块，但是还没有缓存进物理内存

<center><img src="https://miaochenlu.github.io/picture/image-20191122231457120.png" alt="image-20191122231457120" style="zoom:50%;" /></center>



### 1.3.1 page table

如下图所示，page table是page table entry组成的数组。他是被存在内存中的

一个page table entry[PTE]有一个有效位和一个物理页号。

如果有效位是1，说明他已缓存

如果有效位是0

* null代表未分配的
* 如果是未缓存的，这个地址指向该虚拟页在**磁盘**上的起始位置



<center><img src="https://miaochenlu.github.io/picture/image-20191122231829304.png" alt="image-20191122231829304" style="zoom: 50%;" /></center>

#### A. page hit

如果CPU想要读在VP2中的虚拟内存中的一个word

* MMU将虚拟地址作为索引来定位PTE2，并从内存中读取PTE2

* 因为PTE2的有效位是1，所以MMU知道了VP2已经缓存在内存中了。它使用PTE2中的物理页号，构造出这个word的物理地址

<center><img src="https://miaochenlu.github.io/picture/image-20191122232635336.png" alt="image-20191122232635336" style="zoom:50%;" /></center>



#### B. page fault

CPU想要访问VP3中的一个word,但是VP3并未缓存在内存中

* MMU从内存中读取PTE3，从有效位推断VP3未被缓存，触发缺页异常
* 缺页异常调用内核中的缺页异常处理程序，这个程序选择一个牺牲页，比如放在PP3中的VP4。并且修改page table entry，反映出VP4不再缓存在主存里了
  * 如果VP4已经被修改了，内核就会将其复制回磁盘

<center><img src="https://miaochenlu.github.io/picture/image-20191122233502102.png" alt="image-20191122233502102" style="zoom: 50%;" /></center>

* 内核从磁盘复制VP3到内存中的PP3，更新PTE3，然后返回
* 异常处理程序返回时，它会重新启动导致缺页的指令
* 重复同上page hit的过程



#### C. 分配页面

<center><img src="https://miaochenlu.github.io/picture/image-20191122235308295.png" alt="image-20191122235308295" style="zoom:50%;" /></center>



#### 虚拟内存效率怎么样呢？

因为***局部性原理***，虚拟内存工作得非常好

尽管在程序运行过程中程序饮用的不同页面的总数可鞥超出物理内存总的大小，但是局部性原理保证在任意时刻，程序去相遇在一个较小的活动页面[active page]集合上工作，这个集合叫做***工作集***[working set]或者***常驻集合***[resident set]

在初始开销，也就是将工作集页面调度到内存中之后，接下来对这个工作集的引用就会hit,不会产生额外的磁盘流量

但是如果工作集的大小超过了物理内存的大小，就会产生***抖动***[thrashing],这个时候页面会不断换进换出，程序运行的非常慢



## 1.4 虚拟内存作为内存管理的工具

操作系统位每个进程提供了一个独立的页表，也就是一个独立的虚拟地址空间

<center><img src="https://miaochenlu.github.io/picture/image-20191123001058693.png" alt="image-20191123001058693" style="zoom: 50%;" /></center>

虚拟内存的作用

> * 简化链接。
>
>   独立地址空间允许每个进程的内存映像都使用相同的格式。如1.2中地址空间的图所示，代码段总是从0x400000开始，数据段跟在代码段之后,...。
>
>   这样的一致性简化了连接器的设计，允许连接器生成完全链接的可执行文件，这些可执行文件独立于独立内存中的代码和数据位置
>
> 
>
> * 简化加载
>
>   虚拟内存使向内存中加载可执行文件和共享对象文件变得容易。
>
>   要把.text和.data加载到一个新创建的进程中，Linux加载器为代码和数据段分配虚拟页，标记为无效的，并将页表中的地址指向目标文件中适当的位置，这样他处于未缓存的状态。
>
>   但是加载器并不做从磁盘到内存复制数据的工作。在每个页被初次使用时，虚拟内存系统会***按需调页***。
>
>   将一组连续的虚拟页映射到任意一个文件中的任意位置的表示法称为***内存映射***，Linux提供`mmap`系统调用，允许应用程序自己做内存映射
>
> * 简化共享
>
>   如果要共享代码和数据，操作系统hi将不同进程中适当的虚拟页映射到相同的物理页面
>
> * 简化内存分配
>
>   虚拟内存为用户提供了一个简单的分配额外内存的机制。比如调用malloc,操作系统分配一个适当数字个连续的虚拟内存页面，并且将它们映射到物理内存中的任意位置的k个任意的物理页面。操作系统并不需要分配k个连续的物理内存页面，页面可以随机的分散在物理内存中。

<br/>

## 1.5 虚拟内存作为内存保护的工具

每次CPU生成一个地址时，地址翻译硬件都会读一个PTE，通过在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问



<center><img src="https://miaochenlu.github.io/picture/image-20191123112329424.png" alt="image-20191123112329424" style="zoom:50%;" /></center>

如上图示例，每个PTE中加入三个许可位。

* `SUP` 进程是否必须运行在内核模式下才能访问该页
* `READ` 控制读权限
* `WRITE` 控制写权限

如果进程i运行在用户模式下，那么它有读VP0和读写VP1的权限，但是不允许它访问VP2

如果一条指令违反了这些许可条件，CPU就会触发保护故障，将控制传递给一个内核中的一场处理程序。Linux shell一般将这种一场报告为`segmentation fault`



## 1.6 地址翻译

<center><img src="https://miaochenlu.github.io/picture/image-20191123114305099.png" alt="image-20191123114305099" style="zoom:50%;" /></center>

地址翻译是一个N元素的VAS中的元素和一个M元素的PAS中元素的映射

$$MAP: VAS\rightarrow PAS\cup \varnothing$$

$$MAP(A)=\{\begin{aligned}&A' if\,A\,in\,physical\,address\,A'\\ &\varnothing if A \,not\,in \,physical\,memory\end{aligned}$$

<center><img src="https://miaochenlu.github.io/picture/image-20191123114337785.png" alt="image-20191123114337785" style="zoom:50%;" /></center>

#### A. page hit的步骤

* CPU抛出一个虚拟地址，传给MMU
* MMU生成PTE地址，并从高速缓存/主存请求page table entry
* 告诉缓存/主存向MMU返回该PTE
* MMU根据PTE构造出物理地址，并传给高速缓存/主存
* 高速缓存/主存返回所请求的数据给CPU

<center><img src="https://miaochenlu.github.io/picture/image-20191123115551431.png" alt="image-20191123115551431" style="zoom:50%;" /></center>

#### B. Page fault的步骤

* CPU抛出一个虚拟地址，传给MMU
* MMU生成PTE地址，并从高速缓存/主存请求page table entry
* 告诉缓存/主存向MMU返回该PTE
* PTE有效位是0，MMU触发一次异常，传递CPU中的控制到操作系统内核中的缺页异常处理程序
* 缺页处理程序确定物理内存中的牺牲页，如果这个页面已经被修改了，则把它换出到磁盘
* 缺页处理程序页面调入心的页面，并更新内存中的PTE
* 缺页处理程序返回到原来的进程，再次执行导致缺页的指令。

<center><img src="https://miaochenlu.github.io/picture/image-20191123120431404.png" alt="image-20191123120431404" style="zoom:50%;" /></center>



## 1.6.1 结合cache和虚拟内存

使用虚拟地址还是使用物理地址来访问SRAM呢？

> 一般使用物理地址
>
> 使用物理寻址，多个进程同时在高速缓存中有存储块和共享来自相同虚拟页面的块成为很简单的事，而且高速缓存无需处理保护问题，因为访问权限的检查是地址翻译的一部分。

<center><img src="https://miaochenlu.github.io/picture/image-20191123123805540.png" alt="image-20191123123805540" style="zoom:50%;" /></center>

## 1.6.2 利用TLB加速地址翻译

因为page table放在内存中。每次CPU产生一个虚拟地址，MMU就必须查阅一个PTE。

> 在最糟糕的情况下，这会要求从内存多取一次数据，代价是几十到几百个周期
>
> 如果PTE碰巧缓存在L1中，那么开销就下降到1-2个周期

为了减小开销，很多系统都在MMU中包括了一个关于PTE的小缓存，TLB

如下图，虚拟地址被分成

<center><img src="https://miaochenlu.github.io/picture/image-20191123130033197.png" alt="image-20191123130033197" style="zoom:50%;" /></center>

TLB index来索引TLB中的block, TLB tag来检查是否是对应的地址

步骤

* 第一步：CPU产生一个虚拟地址
* 第二、三步：MMU从TLB中取出相应的PTE
* 第四步：MMU将虚拟地址翻译成一个物理地址，并且发送给告诉缓存/主存
* 第五步：告诉缓存/主存将请求的数据返回给CPU

若TLB miss, MMU 必须从L1缓存/主存中取出相应的PTE，新取出的PTE放在TLB中，可能会覆盖一个已经存在的条目

<img src="/Users/jones/Library/Application Support/typora-user-images/image-20191125112258140.png" alt="image-20191125112258140" style="zoom:50%;" />