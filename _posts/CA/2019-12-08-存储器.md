---
title: "CA--storage"
tags: Computer-Architecture
key: page-CAstorage
mathjax: true
author: Chenlu Miao
article_header:
  type: overlay
  theme: dark
  background_color: '#203028'
  background_image:
    gradient: 'linear-gradient(135deg, rgba(34, 139, 87 , .4), rgba(139, 34, 139, .4))'
  background_image:
    src: https://miaochenlu.github.io/picture/IMG_275920191201-193115.png
---

计算机体系结构-存储器层次结构

<center><img src="https://miaochenlu.github.io/picture/image-20191208210849569.png" alt="image-20191208210849569" style="zoom:40%;" /></center>



<!--more-->



# 1. Introduction

<center><img src="https://miaochenlu.github.io/picture/image-20191208134608723.png" alt="image-20191208134608723" style="zoom:50%;" /></center>



## 1.1 缓存性能

CPU execution time

$$=(CPU\, clock\, cycles + Memory\, stall\, cycles)\times Clock\, cycle\, time$$

{:.warning}

这里CPU clock cicles包括handletime  cache hit/miss的时间

<center><img src="https://miaochenlu.github.io/picture/image-20191208135106480.png" alt="image-20191208135106480" style="zoom:60%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191208135244903.png" alt="image-20191208135244903" style="zoom:60%;" /></center>



看一道例题

> a computer with CPI=1 when cache hit.  
>
> 50% instructions are loads and stores;
>
>  2% miss rate, 25 cc miss penalty;
>
> **Q:** how much faster would the computer be if all instructions were cache hits?

Answer:

1. always hit:

CPU execution time = (CPU clocks cycles + Memory stall cycles) * clock cycle

=$$(IC \times CPI + 0) \times clock\,cycle$$

=$$IC \times clock\, cycle$$

<br/>

2. with misses

Memory stall cycles

= $IC \times \frac{Memory\, accesses}{Instruction}\times Miss\, rate\times Miss\, penalty$

=$IC\times(1+0.5)\times 0.02\times 25$

=$IC\times 0.75$

{:.warning}

memory accesses=1.5是因为执行任何一条指令都要访问memory取指令，并且50%的指令是load, store 因此 1+0.5=1.5

CPU execution time = (CPU clocks cycles + Memory stall cycles) $\times$ clock cycle

=$(IC\times 1.0+IC\times 0.75)\times$clock cycle

=$1.75\times $clock cycle

所以比值是1.75



## 1.2 4个存储器层次结构问题

Q1: Where can a block be placed in the upper level? (block placement)

Q2: How is a block found if it is in the upper level? (block identification)

Q3: Which block should be replaced on a miss? (block replacement)

Q4: What happens on a write? (write strategy)

<center><img src="https://miaochenlu.github.io/picture/2019-12-08.7.42.32.png" alt="截屏2019-12-08下午7.42.32" style="zoom:67%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191208194519623.png" alt="image-20191208194519623" style="zoom: 67%;" /></center>



### A. Write Strategy

`Write hit`{:.success}

* write-through: info is written to both the block in the cache and to the block in the lower-level memory
* write-back: info is written only to the block in the cache;  to the main memory only when the modified cache block is replaced[dirty bit]

`Write miss`{:.error}

* Write allocate: data at the missed-**write** location is loaded to cache, followed by a **write**-hit operation  
* No-write allocate[write around]: data at the missed-**write** location is not loaded to cache, and is written directly to the backing store.  ;  *until the program tries to read the block, the data is loaded to cache;*



<center><img src="https://miaochenlu.github.io/picture/image-20191208201918610.png" alt="image-20191208201918610" style="zoom:50%;" /></center>

1. No-Write allocate:  4 misses + 1 hit

<center><img src="https://miaochenlu.github.io/picture/image-20191208202025669.png" alt="image-20191208202025669" style="zoom:50%;" /></center>

2. Write allocate:  2 misses + 3 hits

<center><img src="https://miaochenlu.github.io/picture/image-20191208202722945.png" alt="image-20191208202722945" style="zoom:50%;" /></center>

# 2. 缓存性能



### Hit or Miss: How long will it take?

Average memory access time = Hit time + Miss rate x Miss penalty

* **Example**

> 16KB instr cache + 16KB data cache;
>
>  or, 32KB unified cache;
>
>  36% data transfer instructions;
>
>  (load/store takes 1 extra cc on unified cache)
>
> 1 CC hit; 200 CC miss penalty;

<center><img src="https://miaochenlu.github.io/picture/image-20191208204528711.png" alt="image-20191208204528711" style="zoom:30%;" /></center>

> **Q1:** split cache or unified cache has lower miss rate? 

Answer:

<center><img src="https://miaochenlu.github.io/picture/image-20191208204804983.png" alt="image-20191208204804983" style="zoom:40%;" /></center>

1. split cache

16KB instruction Miss rate

​		= $$\frac{3.82}{1000}/1=0.004$$

16KB data miss rate

​		=$$\frac{40.9}{1000}/0.36=0.114$$

assume 74% of memory accesses are instruction references

Overall miss rate

​		=$$(74\%\times 0.004)+(26\%\times 0.114)=0.0326$$

2. unified cache

Miss rate

=$$\frac{43.3}{1000}/(1.0+0.36)=0.0318$$

> **Q2:** average memory access time?

<center><img src="https://miaochenlu.github.io/picture/image-20191208205644462.png" alt="image-20191208205644462" style="zoom:40%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191208205754992.png" alt="image-20191208205754992" style="zoom:40%;" /></center>



## 2.1 存储器平均访问时间与处理器性能



# 3. 六种基本的缓存优化

我们将所有缺失分成三类

* 强制缺失[Compulsory]

  cold-start/first-reference misses;

* 容量缺失[Capacity]

  cache size limit;

   blocks discarded and later retrieved;

* 冲突缺失

   collision misses: associativity

   a block discarded and later retrieved in a set;

<center><img src="https://miaochenlu.github.io/picture/image-20191208213224033.png" alt="image-20191208213224033" style="zoom:30%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191208213207928.png" alt="image-20191208213207928" style="zoom:30%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191208213148539.png" alt="image-20191208213148539" style="zoom:30%;" /></center>

## 3.1 Larger Block size

* **Reduce** compulsory misses

  ​	Leverage spatial locality

* **Increase** conflict/capacity misses

  ​	Fewer block in the cache

<center><img src="https://miaochenlu.github.io/picture/image-20191208214954621.png" alt="image-20191208214954621" style="zoom: 30%;" /></center>

#### Example

<center><img src="https://miaochenlu.github.io/picture/image-20191208215035983.png" alt="image-20191208215035983" style="zoom:40%;" /></center>

**Answer**

 avg mem access time

​		=hit time + miss rate x miss penalty

{:.info}

 assume 1-CC hit time

 for a 256-byte block in a 256 KB cache:

 avg mem access time

​		= 1 + 0.49% x (80 + 2x256/16) = 1.5 cc

{:.info}

 2x256/16是因为存储器2cc能给cache传回16bytes



## 3.2 Larger cache

* **Reduce** capacity misses

* **Increase** hit time, cost, and power



## 3.3 Higher Associativity

* **Reduce** conflict misses

* **Increase** hit time



## 3.4 Multilevel cache

* **Reduce** miss penalty

<br/>

#### A. Two-level cache

 Add another level of cache between the original cache and memory

* **L1**: small enough to match the clock cycle time of the fast processor;

* **L2**: large enough to capture many accesses that would go to main memory, lessening miss penalty

<center><img src="https://miaochenlu.github.io/picture/image-20191208220714030.png" alt="image-20191208220714030" style="zoom:50%;" /></center>

#### B. Average memory access time

=Hit timeL1 + Miss rateL1 x Miss penaltyL1

=Hit timeL1 + Miss rateL1

 x(Hit timeL2+Miss rateL2xMiss penaltyL2)



#### C. Average mem stalls per instruction

=Misses per instructionL1 x Hit timeL2

 \+ Misses per instrL2 x Miss penaltyL2



#### D. Local miss rate

 the number of misses in a cache

 divided by the total number of mem accesses to <u>this cache</u>;

 {:.info}

分成 Miss rateL1, Miss rateL2

#### E. Global miss rate

 the number of misses in the cache 

 divided by the number of mem accesses generated by the processor;

 {:.info}

L1的全局缺失率Miss rate**L1**,<u>L2的全局缺失率 Miss rateL1 x Miss rateL2</u>



#### Example

> 1000 mem references -> 40 misses in L1 and 20 misses in L2;
>
>  miss penalty from L2 is 200 cc;
>
>  hit time of L2 is 10 cc;
>
>  hit time of L1 is 1 cc;
>
>  1.5 mem references per instruction;

>  **Q: 1.** various miss rates?

 **L1:** local = global

 40/1000 = 4%

 **L2:**

 local: 20/40 = 50%

 global: 20/1000 = 2%

> **Q: 2.** avg mem access time?

average memory access time

=Hit timeL1 + Miss rateL1

 x(Hit timeL2+Miss rateL2xMiss penaltyL2)

=1 + 4% x (10 + 50% x 200)

=5.4

>  **Q: 3.** avg stall cycles per instruction?

average stall cycles per instruction

=Misses per instructionL1 x Hit timeL2

 \+ Misses per instrL2 x Miss penaltyL2

=(1.5x40/1000)x10+(1.5x20/1000)x200

=6.6



## 2.5  Prioritize read misses over writes

* **Reduce** miss penalty

{:.info}

这种方法使得在write buffer将数据写入memory之前，就可以为read操作提供服务



## 2.6 Avoid address translation during indexing cache

虚拟缓存