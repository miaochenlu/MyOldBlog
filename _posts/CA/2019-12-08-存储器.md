---
title: "CA--storage"
tags: Computer-Architecture
key: page-CAstorage
mathjax: true
author: Chenlu Miao
article_header:
  type: overlay
  theme: dark
  background_color: '#203028'
  background_image:
    gradient: 'linear-gradient(135deg, rgba(34, 139, 87 , .4), rgba(139, 34, 139, .4))'
  background_image:
    src: https://miaochenlu.github.io/picture/IMG_275920191201-193115.png
---

计算机体系结构-存储器层次结构

<center><img src="https://miaochenlu.github.io/picture/image-20191208210849569.png" alt="image-20191208210849569" style="zoom:40%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191209103141041.png" alt="image-20191209103141041" style="zoom:30%;" /></center>

<!--more-->



# 1. Introduction

<center><img src="https://miaochenlu.github.io/picture/image-20191208134608723.png" alt="image-20191208134608723" style="zoom:50%;" /></center>



## 1.1 缓存性能

CPU execution time

$$=(CPU\, clock\, cycles + Memory\, stall\, cycles)\times Clock\, cycle\, time$$

{:.warning}

这里CPU clock cicles包括handletime  cache hit/miss的时间

<center><img src="https://miaochenlu.github.io/picture/image-20191208135106480.png" alt="image-20191208135106480" style="zoom:60%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191208135244903.png" alt="image-20191208135244903" style="zoom:60%;" /></center>



看一道例题

> a computer with CPI=1 when cache hit.  
>
> 50% instructions are loads and stores;
>
>  2% miss rate, 25 cc miss penalty;
>
> **Q:** how much faster would the computer be if all instructions were cache hits?

Answer:

1. always hit:

CPU execution time = (CPU clocks cycles + Memory stall cycles) * clock cycle

=$$(IC \times CPI + 0) \times clock\,cycle$$

=$$IC \times clock\, cycle$$

<br/>

2. with misses

Memory stall cycles

= $IC \times \frac{Memory\, accesses}{Instruction}\times Miss\, rate\times Miss\, penalty$

=$IC\times(1+0.5)\times 0.02\times 25$

=$IC\times 0.75$

{:.warning}

memory accesses=1.5是因为执行任何一条指令都要访问memory取指令，并且50%的指令是load, store 因此 1+0.5=1.5

CPU execution time = (CPU clocks cycles + Memory stall cycles) $\times$ clock cycle

=$(IC\times 1.0+IC\times 0.75)\times$clock cycle

=$1.75\times $clock cycle

所以比值是1.75



## 1.2 4个存储器层次结构问题

Q1: Where can a block be placed in the upper level? (block placement)

Q2: How is a block found if it is in the upper level? (block identification)

Q3: Which block should be replaced on a miss? (block replacement)

Q4: What happens on a write? (write strategy)

<center><img src="https://miaochenlu.github.io/picture/2019-12-08.7.42.32.png" alt="截屏2019-12-08下午7.42.32" style="zoom:67%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191208194519623.png" alt="image-20191208194519623" style="zoom: 67%;" /></center>



### A. Write Strategy

`Write hit`{:.success}

* write-through: info is written to both the block in the cache and to the block in the lower-level memory
* write-back: info is written only to the block in the cache;  to the main memory only when the modified cache block is replaced[dirty bit]

`Write miss`{:.error}

* Write allocate: data at the missed-**write** location is loaded to cache, followed by a **write**-hit operation  
* No-write allocate[write around]: data at the missed-**write** location is not loaded to cache, and is written directly to the backing store.  ;  *until the program tries to read the block, the data is loaded to cache;*



<center><img src="https://miaochenlu.github.io/picture/image-20191208201918610.png" alt="image-20191208201918610" style="zoom:50%;" /></center>

1. No-Write allocate:  4 misses + 1 hit

<center><img src="https://miaochenlu.github.io/picture/image-20191208202025669.png" alt="image-20191208202025669" style="zoom:50%;" /></center>

2. Write allocate:  2 misses + 3 hits

<center><img src="https://miaochenlu.github.io/picture/image-20191208202722945.png" alt="image-20191208202722945" style="zoom:50%;" /></center>

# 2. 缓存性能



### Hit or Miss: How long will it take?

Average memory access time = Hit time + Miss rate x Miss penalty

* **Example**

> 16KB instr cache + 16KB data cache;
>
>  or, 32KB unified cache;
>
>  36% data transfer instructions;
>
>  (load/store takes 1 extra cc on unified cache)
>
> 1 CC hit; 200 CC miss penalty;

<center><img src="https://miaochenlu.github.io/picture/image-20191208204528711.png" alt="image-20191208204528711" style="zoom:30%;" /></center>

> **Q1:** split cache or unified cache has lower miss rate? 

Answer:

<center><img src="https://miaochenlu.github.io/picture/image-20191208204804983.png" alt="image-20191208204804983" style="zoom:40%;" /></center>

1. split cache

16KB instruction Miss rate

​		= $$\frac{3.82}{1000}/1=0.004$$

16KB data miss rate

​		=$$\frac{40.9}{1000}/0.36=0.114$$

assume 74% of memory accesses are instruction references

Overall miss rate

​		=$$(74\%\times 0.004)+(26\%\times 0.114)=0.0326$$

2. unified cache

Miss rate

=$$\frac{43.3}{1000}/(1.0+0.36)=0.0318$$

> **Q2:** average memory access time?

<center><img src="https://miaochenlu.github.io/picture/image-20191208205644462.png" alt="image-20191208205644462" style="zoom:40%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191208205754992.png" alt="image-20191208205754992" style="zoom:40%;" /></center>



## 2.1 存储器平均访问时间与处理器性能



# 3. Six Basic Cache Optimizations  

我们将所有缺失分成三类

* 强制缺失[Compulsory]

  cold-start/first-reference misses;

* 容量缺失[Capacity]

  cache size limit;

   blocks discarded and later retrieved;

* 冲突缺失

   collision misses: associativity

   a block discarded and later retrieved in a set;

<center><img src="https://miaochenlu.github.io/picture/image-20191208213224033.png" alt="image-20191208213224033" style="zoom:30%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191208213207928.png" alt="image-20191208213207928" style="zoom:30%;" /></center>

<center><img src="https://miaochenlu.github.io/picture/image-20191208213148539.png" alt="image-20191208213148539" style="zoom:30%;" /></center>

## 3.1 Larger Block size

* **Reduce** compulsory misses

  ​	Leverage spatial locality

* **Reduce** static power

  ​	block size增大，地址里面index位就变多，tag位数就变少，比较时需要的工作量就变少

* **Increase** conflict/capacity misses

  ​	Fewer block in the cache

<center><img src="https://miaochenlu.github.io/picture/image-20191208214954621.png" alt="image-20191208214954621" style="zoom: 30%;" /></center>

#### Example

<center><img src="https://miaochenlu.github.io/picture/image-20191208215035983.png" alt="image-20191208215035983" style="zoom:40%;" /></center>

**Answer**

 avg mem access time

​		=hit time + miss rate x miss penalty

{:.info}

 assume 1-CC hit time

 for a 256-byte block in a 256 KB cache:

 avg mem access time

​		= 1 + 0.49% x (80 + 2x256/16) = 1.5 cc

{:.info}

 2x256/16是因为存储器2cc能给cache传回16bytes



## 3.2 Larger cache

* **Reduce** capacity misses

* **Increase** hit time, cost, and power



## 3.3 Higher Associativity

* **Reduce** conflict misses

* **Increase** hit time



## 3.4 Multilevel cache

* **Reduce** miss penalty

<br/>

#### A. Two-level cache

 Add another level of cache between the original cache and memory

* **L1**: small enough to match the clock cycle time of the fast processor;

* **L2**: large enough to capture many accesses that would go to main memory, lessening miss penalty

<center><img src="https://miaochenlu.github.io/picture/image-20191208220714030.png" alt="image-20191208220714030" style="zoom:50%;" /></center>

#### B. Average memory access time

=Hit timeL1 + Miss rateL1 x Miss penaltyL1

=Hit timeL1 + Miss rateL1

 x(Hit timeL2+Miss rateL2xMiss penaltyL2)



#### C. Average mem stalls per instruction

=Misses per instructionL1 x Hit timeL2

 \+ Misses per instrL2 x Miss penaltyL2



#### D. Local miss rate

 the number of misses in a cache

 divided by the total number of mem accesses to <u>this cache</u>;

 {:.info}

分成 Miss rateL1, Miss rateL2

#### E. Global miss rate

 the number of misses in the cache 

 divided by the number of mem accesses generated by the processor;

 {:.info}

L1的全局缺失率Miss rate**L1**,<u>L2的全局缺失率 Miss rateL1 x Miss rateL2</u>



#### Example

> 1000 mem references -> 40 misses in L1 and 20 misses in L2;
>
>  miss penalty from L2 is 200 cc;
>
>  hit time of L2 is 10 cc;
>
>  hit time of L1 is 1 cc;
>
>  1.5 mem references per instruction;

>  **Q: 1.** various miss rates?

 **L1:** local = global

 40/1000 = 4%

 **L2:**

 local: 20/40 = 50%

 global: 20/1000 = 2%

> **Q: 2.** avg mem access time?

average memory access time

=Hit timeL1 + Miss rateL1

 x(Hit timeL2+Miss rateL2xMiss penaltyL2)

=1 + 4% x (10 + 50% x 200)

=5.4

>  **Q: 3.** avg stall cycles per instruction?

average stall cycles per instruction

=Misses per instructionL1 x Hit timeL2

 \+ Misses per instrL2 x Miss penaltyL2

=(1.5x40/1000)x10+(1.5x20/1000)x200

=6.6



## 2.5  Prioritize read misses over writes

* **Reduce** miss penalty

{:.info}

这种方法使得在write buffer将数据写入memory之前，就可以为read操作提供服务



## 2.6 Avoid address translation during indexing cache

虚拟缓存





# 4. Ten advanced cache optimizations

<img src="/Users/jones/Library/Application Support/typora-user-images/image-20191209100308445.png" alt="image-20191209100308445" style="zoom: 33%;" />





## 4.10 Compiler Prefetching

* **Reduce** miss penalty/rate

* Compiler to insert prefetch instructions to request data before the processor needs it

* **Register** **prefetch**

   load the value into a register

* **Cache** **prefetch**

   load data into the cache

**Example**

```cpp
for(i = 0; i < 3; i = i + 1)
  for(j = 0; j < 100; j = j + 1)
    a[i][j] = b[j][0] * b[j + 1][0]
```

16-byte blocks;

8-byte elements for a and b;

write-back strategy

a\[0][0] miss, copy both a\[0][0],a\[0][1] as one block contains 16/8 = 2;











# 5. Memory

Performance Measures

* **Latency**

{:.warning}

 the time to retrieve the first word of the block

 important for caches;

 harder to reduce;

> **access time**: the time between when a read is requested and when the desired word arrives;
>
> **cycle time**: the minimum time between unrelated requests to memory;
>
>  *or* the minimum time between the start of an access and the start of the next access;

* **Bandwidth** 

{:.warning}

the time to retrieve the rest of this block



## 5.1 RAM

<a href="https://www.zhihu.com/question/30492703">Zhihu Birkee's answer</a>

RAM，Random-Access Memory，即随机存取存储器，其实就是内存，断电会丢失数据。
主要分为SRAM（static）和DRAM（dynamic)。主要的区别在于存储单元，DRAM使用电容电荷进行存储。需要一直刷新充电。SRAM是用锁存器锁住信息，不需要刷新。但也需要充电保持。
关于DRAM，其基本的存储单元如下，利用一个晶体管进行控制电容的充放电。

<img src="/Users/jones/Library/Application Support/typora-user-images/image-20191209104433202.png" alt="image-20191209104433202" style="zoom:50%;" />



DRAM一般的寻址模式，控制的晶体管集成在单个存储单元中。

<img src="/Users/jones/Library/Application Support/typora-user-images/image-20191209104458720.png" alt="image-20191209104458720" style="zoom:50%;" />

## 5.2 SRAM for cache[Static Random Access Memory]

* Six transistors per bit to prevent the information from being disturbed when read

* Don’t need to refresh, so access time is very close to cycle time



## 5.3 DRAM for main memory[Dynamic Random Access Memory]



<img src="https://miaochenlu.github.io/picture/image-20191209105236200.png" alt="image-20191209105236200" style="zoom:30%;" />

<style> .swiper-demo { height: 500px; } .swiper-demo .swiper__slide { display: flex; align-items: center; justify-content: center; font-size: 3rem; color: #fff; } .swiper-demo .swiper__slide:nth-child(even) { background-color: #ff69b4; } .swiper-demo .swiper__slide:nth-child(odd) { background-color: #2593fc; } .swiper-demo--dark .swiper__slide:nth-child(even) { background-color: #312; } .swiper-demo--dark .swiper__slide:nth-child(odd) { background-color: #123; } .swiper-demo--image .swiper__slide:nth-child(n) { background-color: #000; } </style>



<div class="swiper my-3 swiper-demo swiper-demo--image swiper-demo--3">

  <div class="swiper__wrapper">
    <div class="swiper__slide"><img class="lightbox-ignore" src="https://miaochenlu.github.io/picture/image-20191209105411600.png" alt="image-20191209105411600" style="zoom:50%;" /></div>
    <div class="swiper__slide"><img class="lightbox-ignore" src="https://miaochenlu.github.io/picture/image-20191209105418930.png" alt="image-20191209105418930" style="zoom:50%;" /><p>bing row into row buffer</p></div>
    <div class="swiper__slide"><img class="lightbox-ignore" src="https://miaochenlu.github.io/picture/image-20191209105429474.png" alt="image-20191209105429474" style="zoom:50%;"/><p>select Data via Multiplexor</p></div>
    <div class="swiper__slide"><img class="lightbox-ignore" src="https://miaochenlu.github.io/picture/image-20191209105442259.png" alt="image-20191209105442259" style="zoom:50%;"/><p>
      Data selected
      </p></div>
    <div class="swiper__slide"><img class="lightbox-ignore" src="https://miaochenlu.github.io/picture/image-20191209105451917.png" alt="image-20191209105451917" style="zoom:50%;"/><p>
      Row buffer hit
      </p></div>
    <div class="swiper__slide"><img class="lightbox-ignore" src="https://miaochenlu.github.io/picture/image-20191209105459461.png" alt="image-20191209105459461" style="zoom:50%;"/><p>
      Row buffer conflict
      </p></div>
  </div>
  <div class="swiper__button swiper__button--prev fas fa-chevron-left"></div>
  <div class="swiper__button swiper__button--next fas fa-chevron-right"></div></div>





<script> {%- include scripts/lib/swiper.js -%} var SOURCES = window.TEXT_VARIABLES.sources; window.Lazyload.js(SOURCES.jquery, function() { $('.swiper-demo--0').swiper(); $('.swiper-demo--1').swiper(); $('.swiper-demo--2').swiper(); $('.swiper-demo--3').swiper(); $('.swiper-demo--4').swiper({ animation: false }); }); </script>



## 5.6 提高存储器的可靠性

### Error type

* **Soft errors**

{:.info}

 changes to a cell’s contents, not a change in the circuitry

* **Hard errors**

{:.info}

 permanent changes in the operation of one or more memory cells



### Error detection and fix

* **Parity only**

   only one bit of overhead to detect a single error in a sequence of bits;

* **ECC only**

  detect two errors and correct a single error with 8-bit overhead per 64 data bits

* **Chipkill**

  类似于在磁盘中使用RAID方法，它分散数据和ECC信息，在单个存储器芯片完全失效时，可以从其余存储器芯片中重构丢失数据





# 6. Disk





<div class="item">   
  <div class="item__image"> 
    <img class="image image--lg" src="https://miaochenlu.github.io/picture/image-20191209113803942.png" alt="image-20191209113803942" style="zoom:50%;" />
    <img class="image image--lg" src="https://miaochenlu.github.io/picture/image-20191209113823956.png" alt="image-20191209113823956" style="zoom:50%;" />   
  </div>   
  <div class="item__content">     
  <div class="item__header">       
    <h4>Disk</h4>     
  </div>     
  <div class="item__description">     
    <p>Sector: minimum storage unit. A block may span multiple sectors</p>
     <p>Cluster:(dis)contiguous groups of sectors to reduce the overhead of managing on-disk data structures; may span more than one track</p>    
  </div>   
  </div> 
</div>















